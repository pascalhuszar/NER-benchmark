{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flair_fintuned_Conll_03_different_embedd.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WcyMfa4Hk9L2",
        "ZWfGv7h2Gh-W",
        "GZacepc8LhqZ",
        "PF4NtcQlLplO",
        "dI2_i56SxubP",
        "hUYn8Bs3X2rK",
        "r5z0MJFDY72k",
        "tJoKW37iUsyY",
        "tgqgjdvlgM-q",
        "jEmXUeRogl92",
        "tDblEo_YZ2hd",
        "H7-FAsWgRjrA",
        "pX2U3RZmSLa_",
        "IUp-34p9aqz5",
        "p4iWznPwUxO0",
        "6FnOfvlQbpTb",
        "LEkCXfLrZIz8",
        "aHFumxgxbvAF",
        "_oTyHf5jZblf",
        "sMxCCGWWb772",
        "eEinDdOReGtm",
        "i281Wbd5ejlG",
        "u4icwuEtesow",
        "urbljo5SiHLg",
        "veiZOL0ijsD9",
        "ijJcsDyDj6I2",
        "K6g5KjFIbQdD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascalhuszar/flair_notebook/blob/master/Flair_fintuned_Conll_03_different_embedd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2_JcHzIcez_",
        "colab_type": "text"
      },
      "source": [
        "# Walktrough Flair Framework using Conll_03, GermEval_14 as datasets + different embeddings\n",
        "\n",
        "## Embeddings:\n",
        "\n",
        "\n",
        "*   FastText\n",
        "*   BytePair\n",
        "*   Flair\n",
        "*   PooledFlair\n",
        "*   BERT base, Multilingual, German (deepset.ai), GERMAN (dbmdz)\n",
        "*   Hot One\n",
        "*   XLM German+English (CLM/-)\n",
        "*   DistilBERT German, Multilingual\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcyMfa4Hk9L2",
        "colab_type": "text"
      },
      "source": [
        "## 1. Install and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-BVFZXNLLBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if data is on drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQrkdWR8OPdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install flair\n",
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2cEcB-qZwHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# see if flair is installed\n",
        "!pip show flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8dPj23vkHTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import CONLL_03_GERMAN, ColumnCorpus \n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings, OneHotEmbeddings, BertEmbeddings, XLMEmbeddings, BytePairEmbeddings, PooledFlairEmbeddings, CharacterEmbeddings\n",
        "from flair.visual.training_curves import Plotter\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.models import SequenceTagger\n",
        "from typing import List"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWfGv7h2Gh-W",
        "colab_type": "text"
      },
      "source": [
        "## 2. Set the corpus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZacepc8LhqZ",
        "colab_type": "text"
      },
      "source": [
        "### GermEval_14\n",
        "#### Formatted in BIOES-Format\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "349o_xeyGr0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = {0: 'text', 1: 'ner'}\n",
        "data_folder = '/content/drive/My Drive/resources/tasks/conll_03_german/BIOES'\n",
        "\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='trainBIOES.train',\n",
        "                              test_file='testBIOES.test',\n",
        "                              dev_file='devBIOES.dev')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF4NtcQlLplO",
        "colab_type": "text"
      },
      "source": [
        "### Conll_03\n",
        "#### delete_to_bioes if BIO/IOB format is desired\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBnv-jIpLrgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = {0: 'text', 2: 'pos', 4: 'ner'}\n",
        "data_folder = '/content/drive/My Drive/resources/tasks/conll_03_german/BIO + POS'\n",
        "\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              tag_to_bioes='ner',\n",
        "                              train_file='deu.train',\n",
        "                              dev_file='deu.dev',\n",
        "                              test_file='deu.testa')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI2_i56SxubP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Define Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fspFpCHzb4H_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define task + tag dict.\n",
        "tag_type = 'ner'\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "print(tag_dictionary )\n",
        "#print(corpus.train[2].to_tagged_string('ner'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAd8EkjOUeH8",
        "colab_type": "text"
      },
      "source": [
        "## 4. Set Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUYn8Bs3X2rK",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fastext) + BytePairEmbeddings Embeddings\n",
        "#### BytePair for oov-functionality \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj88rDnuYmba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "                                         BytePairEmbeddings('de')                                                 \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5z0MJFDY72k",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fasttext over crawl) + BytePairEmbeddings Embeddings\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6_I18kLZA8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de-crawl'),\n",
        "                                         BytePairEmbeddings('de')                                                   \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJoKW37iUsyY",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fasttext) + Flair Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L43bPcondLAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         FlairEmbeddings('de-forward'),\n",
        "                                         FlairEmbeddings('de-backward'),                                                   \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgqgjdvlgM-q",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fasttext) + Flair (de-history) Embeddings \n",
        "#### Hamburger Anzeiger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpRliKT3gUoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         FlairEmbeddings('de-historic-ha-forward'),\n",
        "                                         FlairEmbeddings('de-historic-ha-backward'),                                                   \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jEmXUeRogl92"
      },
      "source": [
        "### ~ Word (fasttext) + Flair (de-history) Embeddings \n",
        "#### Wiener Zeitung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HqqTOHTsgl97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103917d0-fcfb-49cc-c882-62ddeaab9144"
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         FlairEmbeddings('de-historic-wz-forward'),\n",
        "                                         FlairEmbeddings('de-historic-wz-backward'),                                                   \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 08:54:39,136 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/de-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpq7wvpjql\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1199998928/1199998928 [00:16<00:00, 71006749.88B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 08:54:56,296 copying /tmp/tmpq7wvpjql to cache at /root/.flair/embeddings/de-wiki-fasttext-300d-1M.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 08:55:07,906 removing temp file /tmp/tmpq7wvpjql\n",
            "2020-04-21 08:55:08,091 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/de-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmpehremsz6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 42184395/42184395 [00:04<00:00, 9377676.64B/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 08:55:12,738 copying /tmp/tmpehremsz6 to cache at /root/.flair/embeddings/de-wiki-fasttext-300d-1M\n",
            "2020-04-21 08:55:12,823 removing temp file /tmp/tmpehremsz6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 08:55:19,803 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-stefan-it/lm-historic-wiener-zeitung-forward-v0.1.pt not found in cache, downloading to /tmp/tmpn1othbny\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71605380/71605380 [00:01<00:00, 39296596.61B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 08:55:21,788 copying /tmp/tmpn1othbny to cache at /root/.flair/embeddings/lm-historic-wiener-zeitung-forward-v0.1.pt\n",
            "2020-04-21 08:55:21,851 removing temp file /tmp/tmpn1othbny\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 08:55:40,726 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-stefan-it/lm-historic-wiener-zeitung-backward-v0.1.pt not found in cache, downloading to /tmp/tmpw5_syvgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71605376/71605376 [00:01<00:00, 40011142.01B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 08:55:42,693 copying /tmp/tmpw5_syvgz to cache at /root/.flair/embeddings/lm-historic-wiener-zeitung-backward-v0.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 08:55:42,899 removing temp file /tmp/tmpw5_syvgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDblEo_YZ2hd",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fasttext) + Pooled Flair Embeddings\n",
        "#### Best known configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp24kaCSZ_ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69cc796-a85a-4c41-f426-0a0dad3f9f9d"
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         PooledFlairEmbeddings('german-forward'),\n",
        "                                         PooledFlairEmbeddings('german-backward'),                                                   \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 16:04:26,417 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-mix-german-forward-v0.2rc.pt not found in cache, downloading to /tmp/tmp7tsfxq1d\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 72818995/72818995 [00:01<00:00, 53299890.48B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 16:04:27,957 copying /tmp/tmp7tsfxq1d to cache at /root/.flair/embeddings/lm-mix-german-forward-v0.2rc.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 16:04:28,024 removing temp file /tmp/tmp7tsfxq1d\n",
            "2020-04-21 16:04:46,213 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-mix-german-backward-v0.2rc.pt not found in cache, downloading to /tmp/tmphbu4ir5t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 72818995/72818995 [00:01<00:00, 65624749.98B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 16:04:47,501 copying /tmp/tmphbu4ir5t to cache at /root/.flair/embeddings/lm-mix-german-backward-v0.2rc.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 16:04:47,604 removing temp file /tmp/tmphbu4ir5t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H7-FAsWgRjrA"
      },
      "source": [
        "### Word (fasttext) + CharacterEmbeddings + Flair Embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iIWrvL5WRjrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a7d2a2c9-e68e-4902-da3d-71de63712ac8"
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "                                         CharacterEmbeddings(),\n",
        "                                         FlairEmbeddings('de-forward'),\n",
        "                                         FlairEmbeddings('de-backward'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pX2U3RZmSLa_"
      },
      "source": [
        "### Word (fasttext) + CharacterEmbeddings + Pooled Flair Embeddings \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_CuSYuDSXxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "                                         CharacterEmbeddings(),\n",
        "                                         PooledFlairEmbeddings('german-forward'),\n",
        "                                         PooledFlairEmbeddings('german-backward'), \n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUp-34p9aqz5",
        "colab_type": "text"
      },
      "source": [
        "### PooledFlair Embeddings + dbmdz-BERT-german-cased Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8YpWXpa0Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         PooledFlairEmbeddings('german-forward'),\n",
        "                                         PooledFlairEmbeddings('german-backward'),\n",
        "                                          \n",
        "                                         BertEmbeddings('bert-base-german-dbmdz-cased')\n",
        "                                                                                             \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4iWznPwUxO0",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fasttext) + dbmdz-BERT-german-cased Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S50SDIfAU02X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         BertEmbeddings('bert-base-german-dbmdz-cased'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6FnOfvlQbpTb"
      },
      "source": [
        "### Word (fasttext) + dbmdz-BERT-german-uncased Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KOl8Ry4UbpTf",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         BertEmbeddings('bert-base-german-dbmdz-uncased'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEkCXfLrZIz8",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fasttext) + BERT-base-cased Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQvJ3EDtZOc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         BertEmbeddings('bert-base-cased'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aHFumxgxbvAF"
      },
      "source": [
        "### Word (fasttext) + BERT-base-uncased Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JU2hESKIbvAI",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         BertEmbeddings('bert-base-uncased'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oTyHf5jZblf",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fasttext) + BERT-multilingual-cased Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duMnUjUBZk02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         BertEmbeddings('bert-base-multilingual-cased'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sMxCCGWWb772"
      },
      "source": [
        "### Word (fasttext) + BERT-multilingual-uncased Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ghKuAhb7b776",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         BertEmbeddings('bert-base-multilingual-uncased'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEinDdOReGtm",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fasttext) + BERT-base-german-cased\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNmgr74GeL8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         BertEmbeddings('bert-base-german-cased'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i281Wbd5ejlG",
        "colab_type": "text"
      },
      "source": [
        "### ~ Word (fasttext) + distilbert-base-german-cased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d42UlqrIenHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         BertEmbeddings('distilbert-base-german-cased'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4icwuEtesow",
        "colab_type": "text"
      },
      "source": [
        "### Word (fastext) + distilbert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3raDCpPewPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         BertEmbeddings('distilbert-base-multilingual-cased'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urbljo5SiHLg",
        "colab_type": "text"
      },
      "source": [
        "### One Hot Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPOtsglkiK11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load corpus\n",
        "corpus = \"Own Corpus\"\n",
        "\n",
        "# embed NER tags\n",
        "embeddings = OneHotEmbeddings(corpus=corpus, field='ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veiZOL0ijsD9",
        "colab_type": "text"
      },
      "source": [
        "### Word (fasttext) + XLM (german + english)\n",
        "#### XLM English-German model trained on the concatenation of English and German wikipedia < 6-layer, 1024-hidden, 8-heads >\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxoMCAx8j5qO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         XLMEmbeddings('xlm-mlm-ende-1024'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijJcsDyDj6I2",
        "colab_type": "text"
      },
      "source": [
        "### Word (fasttext) + XLM (german + english)\n",
        "#### XLM English-German model trained with CLM (Causal Language Modeling) on the concatenation of English and German wikipedia < 6-layer, 1024-hidden, 8-heads >\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR7k27cyj--r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize embeddings \n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "                                         WordEmbeddings('de'),\n",
        "\n",
        "                                         XLMEmbeddings('xlm-clm-ende-1024'),\n",
        "                                                                                            \n",
        "]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6g5KjFIbQdD",
        "colab_type": "text"
      },
      "source": [
        "## 5. Set the remaining params and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eqf02nBgSOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize sequence tagger\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type,\n",
        "                                        use_crf=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPqPcqgugcJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize trainer\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCs4NAeKg3aU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc76dc1f-e907-48aa-98f4-446847a22b9d"
      },
      "source": [
        "# start training \n",
        "trainer.train('resources/taggers/example-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150,\n",
        "              checkpoint=True, \n",
        "              embeddings_storage_mode='gpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-14 14:08:31,890 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:08:31,892 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('de')\n",
            "    (list_embedding_1): BytePairEmbeddings(model=1-bpe-de-100000-50)\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=400, out_features=400, bias=True)\n",
            "  (rnn): LSTM(400, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=16, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-14 14:08:31,894 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:08:31,895 Corpus: \"Corpus: 1472 train + 164 dev + 808 test sentences\"\n",
            "2020-05-14 14:08:31,896 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:08:31,897 Parameters:\n",
            "2020-05-14 14:08:31,899  - learning_rate: \"0.1\"\n",
            "2020-05-14 14:08:31,901  - mini_batch_size: \"32\"\n",
            "2020-05-14 14:08:31,903  - patience: \"3\"\n",
            "2020-05-14 14:08:31,904  - anneal_factor: \"0.5\"\n",
            "2020-05-14 14:08:31,905  - max_epochs: \"150\"\n",
            "2020-05-14 14:08:31,906  - shuffle: \"True\"\n",
            "2020-05-14 14:08:31,907  - train_with_dev: \"False\"\n",
            "2020-05-14 14:08:31,909  - batch_growth_annealing: \"False\"\n",
            "2020-05-14 14:08:31,910 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:08:31,912 Model training base path: \"resources/taggers/example-ner\"\n",
            "2020-05-14 14:08:31,913 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:08:31,914 Device: cuda:0\n",
            "2020-05-14 14:08:31,915 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:08:31,916 Embeddings storage mode: gpu\n",
            "2020-05-14 14:08:31,918 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-14 14:08:35,983 epoch 1 - iter 4/46 - loss 82.01364088 - samples/sec: 31.58\n",
            "2020-05-14 14:08:40,392 epoch 1 - iter 8/46 - loss 47.76593637 - samples/sec: 29.17\n",
            "2020-05-14 14:08:44,573 epoch 1 - iter 12/46 - loss 35.15460936 - samples/sec: 30.77\n",
            "2020-05-14 14:08:49,520 epoch 1 - iter 16/46 - loss 29.44958264 - samples/sec: 25.97\n",
            "2020-05-14 14:08:53,903 epoch 1 - iter 20/46 - loss 26.12655244 - samples/sec: 29.34\n",
            "2020-05-14 14:08:58,431 epoch 1 - iter 24/46 - loss 23.31001767 - samples/sec: 28.38\n",
            "2020-05-14 14:09:03,174 epoch 1 - iter 28/46 - loss 21.29893173 - samples/sec: 27.11\n",
            "2020-05-14 14:09:09,016 epoch 1 - iter 32/46 - loss 20.06368393 - samples/sec: 21.99\n",
            "2020-05-14 14:09:14,471 epoch 1 - iter 36/46 - loss 19.06121263 - samples/sec: 23.54\n",
            "2020-05-14 14:09:19,304 epoch 1 - iter 40/46 - loss 18.08345501 - samples/sec: 26.57\n",
            "2020-05-14 14:09:24,165 epoch 1 - iter 44/46 - loss 17.12669203 - samples/sec: 26.43\n",
            "2020-05-14 14:09:26,824 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:09:26,825 EPOCH 1 done: loss 16.6810 - lr 0.1000\n",
            "2020-05-14 14:09:30,271 DEV : loss 7.214709281921387 - score 0.3026\n",
            "2020-05-14 14:09:30,277 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:10:11,785 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:10:20,071 epoch 2 - iter 4/46 - loss 9.95192659 - samples/sec: 26.60\n",
            "2020-05-14 14:10:22,880 epoch 2 - iter 8/46 - loss 9.34306651 - samples/sec: 45.89\n",
            "2020-05-14 14:10:26,404 epoch 2 - iter 12/46 - loss 8.71582317 - samples/sec: 36.51\n",
            "2020-05-14 14:10:30,346 epoch 2 - iter 16/46 - loss 8.20968327 - samples/sec: 32.65\n",
            "2020-05-14 14:10:33,461 epoch 2 - iter 20/46 - loss 8.17659571 - samples/sec: 41.32\n",
            "2020-05-14 14:10:37,209 epoch 2 - iter 24/46 - loss 8.17485613 - samples/sec: 34.30\n",
            "2020-05-14 14:10:41,519 epoch 2 - iter 28/46 - loss 8.28959586 - samples/sec: 29.82\n",
            "2020-05-14 14:10:45,448 epoch 2 - iter 32/46 - loss 7.98388527 - samples/sec: 32.75\n",
            "2020-05-14 14:10:48,187 epoch 2 - iter 36/46 - loss 7.74369135 - samples/sec: 47.01\n",
            "2020-05-14 14:10:50,745 epoch 2 - iter 40/46 - loss 7.64075823 - samples/sec: 50.38\n",
            "2020-05-14 14:10:53,970 epoch 2 - iter 44/46 - loss 7.59756646 - samples/sec: 39.94\n",
            "2020-05-14 14:10:55,551 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:10:55,552 EPOCH 2 done: loss 7.5117 - lr 0.1000\n",
            "2020-05-14 14:10:57,441 DEV : loss 5.517658233642578 - score 0.5275\n",
            "2020-05-14 14:10:57,450 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:11:40,170 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:11:45,014 epoch 3 - iter 4/46 - loss 7.08273840 - samples/sec: 26.91\n",
            "2020-05-14 14:11:47,667 epoch 3 - iter 8/46 - loss 6.71157461 - samples/sec: 48.60\n",
            "2020-05-14 14:11:51,544 epoch 3 - iter 12/46 - loss 7.20255673 - samples/sec: 33.17\n",
            "2020-05-14 14:11:55,928 epoch 3 - iter 16/46 - loss 7.07203072 - samples/sec: 29.35\n",
            "2020-05-14 14:11:58,551 epoch 3 - iter 20/46 - loss 6.47627189 - samples/sec: 49.15\n",
            "2020-05-14 14:12:02,626 epoch 3 - iter 24/46 - loss 6.85785037 - samples/sec: 31.56\n",
            "2020-05-14 14:12:05,106 epoch 3 - iter 28/46 - loss 6.64116495 - samples/sec: 52.02\n",
            "2020-05-14 14:12:09,312 epoch 3 - iter 32/46 - loss 6.64523508 - samples/sec: 30.57\n",
            "2020-05-14 14:12:12,221 epoch 3 - iter 36/46 - loss 6.50295704 - samples/sec: 44.30\n",
            "2020-05-14 14:12:15,400 epoch 3 - iter 40/46 - loss 6.35191404 - samples/sec: 40.47\n",
            "2020-05-14 14:12:18,769 epoch 3 - iter 44/46 - loss 6.42965403 - samples/sec: 38.21\n",
            "2020-05-14 14:12:20,540 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:12:20,541 EPOCH 3 done: loss 6.3980 - lr 0.1000\n",
            "2020-05-14 14:12:22,430 DEV : loss 4.970695495605469 - score 0.5412\n",
            "2020-05-14 14:12:22,436 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:13:04,002 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:13:07,872 epoch 4 - iter 4/46 - loss 5.04744589 - samples/sec: 34.96\n",
            "2020-05-14 14:13:11,811 epoch 4 - iter 8/46 - loss 4.72400144 - samples/sec: 32.65\n",
            "2020-05-14 14:13:15,311 epoch 4 - iter 12/46 - loss 5.25848164 - samples/sec: 36.77\n",
            "2020-05-14 14:13:18,834 epoch 4 - iter 16/46 - loss 6.05484997 - samples/sec: 36.54\n",
            "2020-05-14 14:13:22,299 epoch 4 - iter 20/46 - loss 6.18787283 - samples/sec: 37.13\n",
            "2020-05-14 14:13:24,993 epoch 4 - iter 24/46 - loss 6.05396845 - samples/sec: 47.83\n",
            "2020-05-14 14:13:29,300 epoch 4 - iter 28/46 - loss 6.26030593 - samples/sec: 29.85\n",
            "2020-05-14 14:13:33,338 epoch 4 - iter 32/46 - loss 6.08193846 - samples/sec: 31.84\n",
            "2020-05-14 14:13:36,923 epoch 4 - iter 36/46 - loss 5.95991802 - samples/sec: 35.89\n",
            "2020-05-14 14:13:41,335 epoch 4 - iter 40/46 - loss 6.05140110 - samples/sec: 29.12\n",
            "2020-05-14 14:13:44,085 epoch 4 - iter 44/46 - loss 5.96725739 - samples/sec: 46.88\n",
            "2020-05-14 14:13:46,099 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:13:46,100 EPOCH 4 done: loss 5.9335 - lr 0.1000\n",
            "2020-05-14 14:13:47,915 DEV : loss 4.745165824890137 - score 0.5605\n",
            "2020-05-14 14:13:47,920 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:14:30,098 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:14:33,438 epoch 5 - iter 4/46 - loss 7.41221702 - samples/sec: 38.57\n",
            "2020-05-14 14:14:37,932 epoch 5 - iter 8/46 - loss 7.34606731 - samples/sec: 28.59\n",
            "2020-05-14 14:14:42,066 epoch 5 - iter 12/46 - loss 6.60857332 - samples/sec: 31.13\n",
            "2020-05-14 14:14:45,142 epoch 5 - iter 16/46 - loss 6.32460897 - samples/sec: 41.85\n",
            "2020-05-14 14:14:48,230 epoch 5 - iter 20/46 - loss 5.95301062 - samples/sec: 41.72\n",
            "2020-05-14 14:14:51,450 epoch 5 - iter 24/46 - loss 6.09666178 - samples/sec: 39.96\n",
            "2020-05-14 14:14:55,692 epoch 5 - iter 28/46 - loss 5.82905063 - samples/sec: 30.31\n",
            "2020-05-14 14:14:59,113 epoch 5 - iter 32/46 - loss 5.62705781 - samples/sec: 37.65\n",
            "2020-05-14 14:15:02,659 epoch 5 - iter 36/46 - loss 5.55258357 - samples/sec: 36.30\n",
            "2020-05-14 14:15:06,217 epoch 5 - iter 40/46 - loss 5.51275999 - samples/sec: 36.15\n",
            "2020-05-14 14:15:10,104 epoch 5 - iter 44/46 - loss 5.55088488 - samples/sec: 33.10\n",
            "2020-05-14 14:15:12,070 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:15:12,074 EPOCH 5 done: loss 5.5149 - lr 0.1000\n",
            "2020-05-14 14:15:14,001 DEV : loss 4.919672012329102 - score 0.5781\n",
            "2020-05-14 14:15:14,009 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:15:57,672 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:16:01,442 epoch 6 - iter 4/46 - loss 4.43591642 - samples/sec: 34.00\n",
            "2020-05-14 14:16:05,543 epoch 6 - iter 8/46 - loss 4.78174791 - samples/sec: 31.35\n",
            "2020-05-14 14:16:09,452 epoch 6 - iter 12/46 - loss 4.72135262 - samples/sec: 32.91\n",
            "2020-05-14 14:16:12,359 epoch 6 - iter 16/46 - loss 4.86639670 - samples/sec: 44.28\n",
            "2020-05-14 14:16:17,658 epoch 6 - iter 20/46 - loss 5.22749057 - samples/sec: 24.25\n",
            "2020-05-14 14:16:21,294 epoch 6 - iter 24/46 - loss 5.60115933 - samples/sec: 35.39\n",
            "2020-05-14 14:16:24,276 epoch 6 - iter 28/46 - loss 5.44816156 - samples/sec: 43.17\n",
            "2020-05-14 14:16:27,697 epoch 6 - iter 32/46 - loss 5.48193956 - samples/sec: 37.62\n",
            "2020-05-14 14:16:31,443 epoch 6 - iter 36/46 - loss 5.46323289 - samples/sec: 34.33\n",
            "2020-05-14 14:16:34,699 epoch 6 - iter 40/46 - loss 5.36382954 - samples/sec: 39.53\n",
            "2020-05-14 14:16:38,100 epoch 6 - iter 44/46 - loss 5.26825437 - samples/sec: 37.87\n",
            "2020-05-14 14:16:40,296 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:16:40,297 EPOCH 6 done: loss 5.2955 - lr 0.1000\n",
            "2020-05-14 14:16:42,141 DEV : loss 4.380105495452881 - score 0.6132\n",
            "2020-05-14 14:16:42,146 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:17:23,677 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:17:27,702 epoch 7 - iter 4/46 - loss 6.14815438 - samples/sec: 33.36\n",
            "2020-05-14 14:17:31,496 epoch 7 - iter 8/46 - loss 5.85426217 - samples/sec: 33.92\n",
            "2020-05-14 14:17:35,777 epoch 7 - iter 12/46 - loss 6.08131512 - samples/sec: 30.02\n",
            "2020-05-14 14:17:38,422 epoch 7 - iter 16/46 - loss 5.67470336 - samples/sec: 48.70\n",
            "2020-05-14 14:17:42,118 epoch 7 - iter 20/46 - loss 5.58355885 - samples/sec: 34.79\n",
            "2020-05-14 14:17:45,182 epoch 7 - iter 24/46 - loss 5.40914999 - samples/sec: 42.03\n",
            "2020-05-14 14:17:49,241 epoch 7 - iter 28/46 - loss 5.26424482 - samples/sec: 31.67\n",
            "2020-05-14 14:17:53,041 epoch 7 - iter 32/46 - loss 5.09033067 - samples/sec: 33.85\n",
            "2020-05-14 14:17:56,310 epoch 7 - iter 36/46 - loss 5.03100516 - samples/sec: 39.36\n",
            "2020-05-14 14:17:59,544 epoch 7 - iter 40/46 - loss 5.15956506 - samples/sec: 39.85\n",
            "2020-05-14 14:18:04,317 epoch 7 - iter 44/46 - loss 5.09404420 - samples/sec: 26.92\n",
            "2020-05-14 14:18:06,010 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:18:06,011 EPOCH 7 done: loss 5.0580 - lr 0.1000\n",
            "2020-05-14 14:18:07,937 DEV : loss 4.077770233154297 - score 0.6401\n",
            "2020-05-14 14:18:07,946 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:18:50,552 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:18:55,160 epoch 8 - iter 4/46 - loss 5.56553704 - samples/sec: 27.93\n",
            "2020-05-14 14:18:59,794 epoch 8 - iter 8/46 - loss 5.55469599 - samples/sec: 27.73\n",
            "2020-05-14 14:19:03,501 epoch 8 - iter 12/46 - loss 5.39205760 - samples/sec: 34.68\n",
            "2020-05-14 14:19:08,479 epoch 8 - iter 16/46 - loss 5.59411426 - samples/sec: 25.83\n",
            "2020-05-14 14:19:11,203 epoch 8 - iter 20/46 - loss 5.19279634 - samples/sec: 47.28\n",
            "2020-05-14 14:19:13,358 epoch 8 - iter 24/46 - loss 4.90524710 - samples/sec: 59.95\n",
            "2020-05-14 14:19:16,432 epoch 8 - iter 28/46 - loss 4.99095872 - samples/sec: 41.89\n",
            "2020-05-14 14:19:19,961 epoch 8 - iter 32/46 - loss 4.91118283 - samples/sec: 36.50\n",
            "2020-05-14 14:19:23,781 epoch 8 - iter 36/46 - loss 4.74820638 - samples/sec: 33.68\n",
            "2020-05-14 14:19:26,931 epoch 8 - iter 40/46 - loss 4.88072367 - samples/sec: 40.86\n",
            "2020-05-14 14:19:29,415 epoch 8 - iter 44/46 - loss 4.83671195 - samples/sec: 51.95\n",
            "2020-05-14 14:19:31,529 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:19:31,530 EPOCH 8 done: loss 4.8485 - lr 0.1000\n",
            "2020-05-14 14:19:34,485 DEV : loss 4.2328715324401855 - score 0.6208\n",
            "2020-05-14 14:19:34,494 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:19:47,654 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:19:51,567 epoch 9 - iter 4/46 - loss 3.75367641 - samples/sec: 32.73\n",
            "2020-05-14 14:19:55,425 epoch 9 - iter 8/46 - loss 4.37582967 - samples/sec: 33.33\n",
            "2020-05-14 14:19:58,387 epoch 9 - iter 12/46 - loss 4.17992689 - samples/sec: 43.52\n",
            "2020-05-14 14:20:02,252 epoch 9 - iter 16/46 - loss 4.26224983 - samples/sec: 33.30\n",
            "2020-05-14 14:20:06,447 epoch 9 - iter 20/46 - loss 4.73122611 - samples/sec: 30.65\n",
            "2020-05-14 14:20:11,120 epoch 9 - iter 24/46 - loss 4.91147717 - samples/sec: 27.51\n",
            "2020-05-14 14:20:13,932 epoch 9 - iter 28/46 - loss 5.16576769 - samples/sec: 45.83\n",
            "2020-05-14 14:20:16,630 epoch 9 - iter 32/46 - loss 4.95813581 - samples/sec: 47.77\n",
            "2020-05-14 14:20:19,621 epoch 9 - iter 36/46 - loss 4.91329822 - samples/sec: 43.05\n",
            "2020-05-14 14:20:23,038 epoch 9 - iter 40/46 - loss 4.88948767 - samples/sec: 37.65\n",
            "2020-05-14 14:20:26,641 epoch 9 - iter 44/46 - loss 4.82540473 - samples/sec: 35.71\n",
            "2020-05-14 14:20:28,135 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:20:28,136 EPOCH 9 done: loss 4.7905 - lr 0.1000\n",
            "2020-05-14 14:20:30,006 DEV : loss 3.995786666870117 - score 0.6227\n",
            "2020-05-14 14:20:30,015 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 14:20:43,040 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:20:46,543 epoch 10 - iter 4/46 - loss 4.78936106 - samples/sec: 36.56\n",
            "2020-05-14 14:20:50,392 epoch 10 - iter 8/46 - loss 4.68148881 - samples/sec: 33.42\n",
            "2020-05-14 14:20:54,145 epoch 10 - iter 12/46 - loss 5.16886735 - samples/sec: 34.29\n",
            "2020-05-14 14:20:58,780 epoch 10 - iter 16/46 - loss 4.93877587 - samples/sec: 27.73\n",
            "2020-05-14 14:21:03,186 epoch 10 - iter 20/46 - loss 4.80135299 - samples/sec: 29.19\n",
            "2020-05-14 14:21:06,618 epoch 10 - iter 24/46 - loss 4.60767596 - samples/sec: 37.51\n",
            "2020-05-14 14:21:10,229 epoch 10 - iter 28/46 - loss 4.44629537 - samples/sec: 35.64\n",
            "2020-05-14 14:21:14,160 epoch 10 - iter 32/46 - loss 4.67044565 - samples/sec: 32.72\n",
            "2020-05-14 14:21:16,851 epoch 10 - iter 36/46 - loss 4.68018027 - samples/sec: 47.92\n",
            "2020-05-14 14:21:19,571 epoch 10 - iter 40/46 - loss 4.59881484 - samples/sec: 47.36\n",
            "2020-05-14 14:21:22,969 epoch 10 - iter 44/46 - loss 4.56482392 - samples/sec: 37.86\n",
            "2020-05-14 14:21:24,883 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:21:24,884 EPOCH 10 done: loss 4.6637 - lr 0.1000\n",
            "2020-05-14 14:21:26,790 DEV : loss 3.906325101852417 - score 0.6307\n",
            "2020-05-14 14:21:26,798 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 14:21:40,319 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:21:44,029 epoch 11 - iter 4/46 - loss 4.81761205 - samples/sec: 34.57\n",
            "2020-05-14 14:21:48,515 epoch 11 - iter 8/46 - loss 4.87694848 - samples/sec: 28.65\n",
            "2020-05-14 14:21:52,543 epoch 11 - iter 12/46 - loss 5.03034627 - samples/sec: 31.92\n",
            "2020-05-14 14:21:55,483 epoch 11 - iter 16/46 - loss 4.68141243 - samples/sec: 43.86\n",
            "2020-05-14 14:21:59,233 epoch 11 - iter 20/46 - loss 4.49554579 - samples/sec: 34.33\n",
            "2020-05-14 14:22:03,894 epoch 11 - iter 24/46 - loss 4.78621157 - samples/sec: 27.59\n",
            "2020-05-14 14:22:07,530 epoch 11 - iter 28/46 - loss 4.79503474 - samples/sec: 35.37\n",
            "2020-05-14 14:22:10,350 epoch 11 - iter 32/46 - loss 4.78403174 - samples/sec: 45.70\n",
            "2020-05-14 14:22:13,244 epoch 11 - iter 36/46 - loss 4.72749536 - samples/sec: 44.53\n",
            "2020-05-14 14:22:15,652 epoch 11 - iter 40/46 - loss 4.61297666 - samples/sec: 53.61\n",
            "2020-05-14 14:22:19,600 epoch 11 - iter 44/46 - loss 4.50111509 - samples/sec: 32.59\n",
            "2020-05-14 14:22:21,533 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:22:21,534 EPOCH 11 done: loss 4.4869 - lr 0.1000\n",
            "2020-05-14 14:22:23,402 DEV : loss 3.8502116203308105 - score 0.6304\n",
            "Epoch    11: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-05-14 14:22:23,410 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 14:22:36,572 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:22:41,312 epoch 12 - iter 4/46 - loss 3.56626678 - samples/sec: 27.01\n",
            "2020-05-14 14:22:44,632 epoch 12 - iter 8/46 - loss 3.53542608 - samples/sec: 38.76\n",
            "2020-05-14 14:22:48,464 epoch 12 - iter 12/46 - loss 3.78580105 - samples/sec: 33.58\n",
            "2020-05-14 14:22:51,883 epoch 12 - iter 16/46 - loss 3.74375847 - samples/sec: 37.62\n",
            "2020-05-14 14:22:54,768 epoch 12 - iter 20/46 - loss 3.76638882 - samples/sec: 44.67\n",
            "2020-05-14 14:22:58,628 epoch 12 - iter 24/46 - loss 4.01075597 - samples/sec: 33.31\n",
            "2020-05-14 14:23:02,502 epoch 12 - iter 28/46 - loss 4.03333177 - samples/sec: 33.21\n",
            "2020-05-14 14:23:06,045 epoch 12 - iter 32/46 - loss 4.03760724 - samples/sec: 36.33\n",
            "2020-05-14 14:23:09,508 epoch 12 - iter 36/46 - loss 4.15772220 - samples/sec: 37.17\n",
            "2020-05-14 14:23:12,773 epoch 12 - iter 40/46 - loss 4.21843634 - samples/sec: 39.43\n",
            "2020-05-14 14:23:18,425 epoch 12 - iter 44/46 - loss 4.24982620 - samples/sec: 22.72\n",
            "2020-05-14 14:23:19,796 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:23:19,804 EPOCH 12 done: loss 4.2480 - lr 0.0500\n",
            "2020-05-14 14:23:21,730 DEV : loss 3.725557804107666 - score 0.6449\n",
            "2020-05-14 14:23:21,744 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:24:03,332 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:24:07,497 epoch 13 - iter 4/46 - loss 5.53443491 - samples/sec: 35.85\n",
            "2020-05-14 14:24:12,215 epoch 13 - iter 8/46 - loss 5.55423206 - samples/sec: 27.25\n",
            "2020-05-14 14:24:16,675 epoch 13 - iter 12/46 - loss 5.17766899 - samples/sec: 28.81\n",
            "2020-05-14 14:24:20,041 epoch 13 - iter 16/46 - loss 4.93201387 - samples/sec: 38.28\n",
            "2020-05-14 14:24:23,227 epoch 13 - iter 20/46 - loss 4.82251291 - samples/sec: 40.48\n",
            "2020-05-14 14:24:26,634 epoch 13 - iter 24/46 - loss 4.67863931 - samples/sec: 37.78\n",
            "2020-05-14 14:24:29,754 epoch 13 - iter 28/46 - loss 4.45947570 - samples/sec: 41.32\n",
            "2020-05-14 14:24:33,596 epoch 13 - iter 32/46 - loss 4.35768131 - samples/sec: 33.52\n",
            "2020-05-14 14:24:36,579 epoch 13 - iter 36/46 - loss 4.27155630 - samples/sec: 43.19\n",
            "2020-05-14 14:24:39,941 epoch 13 - iter 40/46 - loss 4.28721425 - samples/sec: 38.29\n",
            "2020-05-14 14:24:44,226 epoch 13 - iter 44/46 - loss 4.34188378 - samples/sec: 30.00\n",
            "2020-05-14 14:24:46,606 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:24:46,607 EPOCH 13 done: loss 4.2658 - lr 0.0500\n",
            "2020-05-14 14:24:48,544 DEV : loss 3.6667537689208984 - score 0.6426\n",
            "2020-05-14 14:24:48,550 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:25:01,741 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:25:05,458 epoch 14 - iter 4/46 - loss 3.94879174 - samples/sec: 34.51\n",
            "2020-05-14 14:25:09,060 epoch 14 - iter 8/46 - loss 3.62806591 - samples/sec: 35.71\n",
            "2020-05-14 14:25:13,108 epoch 14 - iter 12/46 - loss 4.24005928 - samples/sec: 31.78\n",
            "2020-05-14 14:25:15,945 epoch 14 - iter 16/46 - loss 4.44204347 - samples/sec: 45.43\n",
            "2020-05-14 14:25:20,083 epoch 14 - iter 20/46 - loss 4.30291158 - samples/sec: 31.08\n",
            "2020-05-14 14:25:23,053 epoch 14 - iter 24/46 - loss 4.16829220 - samples/sec: 43.39\n",
            "2020-05-14 14:25:26,381 epoch 14 - iter 28/46 - loss 4.30873850 - samples/sec: 38.69\n",
            "2020-05-14 14:25:31,014 epoch 14 - iter 32/46 - loss 4.39292189 - samples/sec: 27.73\n",
            "2020-05-14 14:25:33,608 epoch 14 - iter 36/46 - loss 4.33153588 - samples/sec: 49.68\n",
            "2020-05-14 14:25:36,959 epoch 14 - iter 40/46 - loss 4.22959990 - samples/sec: 38.46\n",
            "2020-05-14 14:25:40,050 epoch 14 - iter 44/46 - loss 4.20086719 - samples/sec: 41.66\n",
            "2020-05-14 14:25:41,800 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:25:41,802 EPOCH 14 done: loss 4.1648 - lr 0.0500\n",
            "2020-05-14 14:25:43,726 DEV : loss 3.73207426071167 - score 0.65\n",
            "2020-05-14 14:25:43,734 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:26:25,766 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:26:29,721 epoch 15 - iter 4/46 - loss 3.95824993 - samples/sec: 32.79\n",
            "2020-05-14 14:26:33,509 epoch 15 - iter 8/46 - loss 4.17989987 - samples/sec: 33.97\n",
            "2020-05-14 14:26:37,335 epoch 15 - iter 12/46 - loss 3.97200964 - samples/sec: 33.63\n",
            "2020-05-14 14:26:41,294 epoch 15 - iter 16/46 - loss 4.00643580 - samples/sec: 32.50\n",
            "2020-05-14 14:26:45,171 epoch 15 - iter 20/46 - loss 4.13828863 - samples/sec: 33.19\n",
            "2020-05-14 14:26:48,793 epoch 15 - iter 24/46 - loss 4.09623471 - samples/sec: 35.51\n",
            "2020-05-14 14:26:51,927 epoch 15 - iter 28/46 - loss 3.96104131 - samples/sec: 41.15\n",
            "2020-05-14 14:26:54,862 epoch 15 - iter 32/46 - loss 3.90381298 - samples/sec: 43.88\n",
            "2020-05-14 14:26:58,165 epoch 15 - iter 36/46 - loss 4.06834760 - samples/sec: 39.04\n",
            "2020-05-14 14:27:01,562 epoch 15 - iter 40/46 - loss 4.04692602 - samples/sec: 37.93\n",
            "2020-05-14 14:27:05,566 epoch 15 - iter 44/46 - loss 4.08194555 - samples/sec: 32.11\n",
            "2020-05-14 14:27:06,846 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:27:06,847 EPOCH 15 done: loss 4.0178 - lr 0.0500\n",
            "2020-05-14 14:27:08,784 DEV : loss 3.634291410446167 - score 0.6584\n",
            "2020-05-14 14:27:08,794 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:27:50,863 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:27:55,064 epoch 16 - iter 4/46 - loss 2.57283288 - samples/sec: 32.62\n",
            "2020-05-14 14:27:58,927 epoch 16 - iter 8/46 - loss 3.50597918 - samples/sec: 33.30\n",
            "2020-05-14 14:28:02,838 epoch 16 - iter 12/46 - loss 3.69916306 - samples/sec: 32.89\n",
            "2020-05-14 14:28:06,223 epoch 16 - iter 16/46 - loss 3.68260981 - samples/sec: 38.04\n",
            "2020-05-14 14:28:09,351 epoch 16 - iter 20/46 - loss 3.91461127 - samples/sec: 41.16\n",
            "2020-05-14 14:28:12,174 epoch 16 - iter 24/46 - loss 3.76913360 - samples/sec: 45.64\n",
            "2020-05-14 14:28:17,051 epoch 16 - iter 28/46 - loss 3.86294100 - samples/sec: 26.36\n",
            "2020-05-14 14:28:19,846 epoch 16 - iter 32/46 - loss 3.85638843 - samples/sec: 46.11\n",
            "2020-05-14 14:28:23,144 epoch 16 - iter 36/46 - loss 3.85712547 - samples/sec: 39.02\n",
            "2020-05-14 14:28:26,999 epoch 16 - iter 40/46 - loss 3.95001135 - samples/sec: 33.37\n",
            "2020-05-14 14:28:30,837 epoch 16 - iter 44/46 - loss 4.16704033 - samples/sec: 33.51\n",
            "2020-05-14 14:28:32,657 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:28:32,658 EPOCH 16 done: loss 4.1185 - lr 0.0500\n",
            "2020-05-14 14:28:34,564 DEV : loss 3.662309408187866 - score 0.6525\n",
            "2020-05-14 14:28:34,569 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:28:47,656 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:28:51,828 epoch 17 - iter 4/46 - loss 3.42585748 - samples/sec: 30.70\n",
            "2020-05-14 14:28:56,368 epoch 17 - iter 8/46 - loss 3.87858999 - samples/sec: 28.30\n",
            "2020-05-14 14:28:59,351 epoch 17 - iter 12/46 - loss 3.93420299 - samples/sec: 43.18\n",
            "2020-05-14 14:29:03,417 epoch 17 - iter 16/46 - loss 4.11466262 - samples/sec: 31.62\n",
            "2020-05-14 14:29:06,642 epoch 17 - iter 20/46 - loss 4.06826724 - samples/sec: 39.93\n",
            "2020-05-14 14:29:10,937 epoch 17 - iter 24/46 - loss 4.00804680 - samples/sec: 29.95\n",
            "2020-05-14 14:29:14,160 epoch 17 - iter 28/46 - loss 3.86172342 - samples/sec: 39.99\n",
            "2020-05-14 14:29:18,617 epoch 17 - iter 32/46 - loss 4.04160357 - samples/sec: 28.85\n",
            "2020-05-14 14:29:21,903 epoch 17 - iter 36/46 - loss 4.20067762 - samples/sec: 39.19\n",
            "2020-05-14 14:29:25,706 epoch 17 - iter 40/46 - loss 4.13350784 - samples/sec: 33.81\n",
            "2020-05-14 14:29:28,812 epoch 17 - iter 44/46 - loss 4.03272886 - samples/sec: 41.46\n",
            "2020-05-14 14:29:30,496 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:29:30,497 EPOCH 17 done: loss 4.0638 - lr 0.0500\n",
            "2020-05-14 14:29:32,389 DEV : loss 3.6430163383483887 - score 0.6554\n",
            "2020-05-14 14:29:32,398 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 14:29:45,528 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:29:49,146 epoch 18 - iter 4/46 - loss 2.84549135 - samples/sec: 35.41\n",
            "2020-05-14 14:29:51,628 epoch 18 - iter 8/46 - loss 3.25995159 - samples/sec: 51.90\n",
            "2020-05-14 14:29:56,449 epoch 18 - iter 12/46 - loss 3.90094815 - samples/sec: 26.67\n",
            "2020-05-14 14:29:58,774 epoch 18 - iter 16/46 - loss 3.94185776 - samples/sec: 55.56\n",
            "2020-05-14 14:30:01,608 epoch 18 - iter 20/46 - loss 3.84868009 - samples/sec: 45.49\n",
            "2020-05-14 14:30:05,787 epoch 18 - iter 24/46 - loss 3.69666206 - samples/sec: 30.78\n",
            "2020-05-14 14:30:09,060 epoch 18 - iter 28/46 - loss 3.64658338 - samples/sec: 39.35\n",
            "2020-05-14 14:30:12,346 epoch 18 - iter 32/46 - loss 3.75776175 - samples/sec: 39.19\n",
            "2020-05-14 14:30:17,198 epoch 18 - iter 36/46 - loss 3.96015322 - samples/sec: 26.52\n",
            "2020-05-14 14:30:20,004 epoch 18 - iter 40/46 - loss 3.94831933 - samples/sec: 45.89\n",
            "2020-05-14 14:30:23,380 epoch 18 - iter 44/46 - loss 4.03380281 - samples/sec: 38.10\n",
            "2020-05-14 14:30:25,189 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:30:25,190 EPOCH 18 done: loss 4.0413 - lr 0.0500\n",
            "2020-05-14 14:30:27,095 DEV : loss 3.7385640144348145 - score 0.6653\n",
            "2020-05-14 14:30:27,103 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:31:08,439 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:31:13,574 epoch 19 - iter 4/46 - loss 6.10773408 - samples/sec: 28.54\n",
            "2020-05-14 14:31:16,568 epoch 19 - iter 8/46 - loss 4.96010596 - samples/sec: 43.03\n",
            "2020-05-14 14:31:20,466 epoch 19 - iter 12/46 - loss 4.72217653 - samples/sec: 32.99\n",
            "2020-05-14 14:31:23,121 epoch 19 - iter 16/46 - loss 4.42208882 - samples/sec: 48.54\n",
            "2020-05-14 14:31:26,194 epoch 19 - iter 20/46 - loss 4.26374701 - samples/sec: 41.92\n",
            "2020-05-14 14:31:29,354 epoch 19 - iter 24/46 - loss 4.03136044 - samples/sec: 40.76\n",
            "2020-05-14 14:31:32,434 epoch 19 - iter 28/46 - loss 3.94537127 - samples/sec: 41.85\n",
            "2020-05-14 14:31:35,892 epoch 19 - iter 32/46 - loss 3.84229108 - samples/sec: 37.21\n",
            "2020-05-14 14:31:40,036 epoch 19 - iter 36/46 - loss 3.91340934 - samples/sec: 31.03\n",
            "2020-05-14 14:31:44,072 epoch 19 - iter 40/46 - loss 4.01798357 - samples/sec: 31.86\n",
            "2020-05-14 14:31:47,010 epoch 19 - iter 44/46 - loss 3.90819945 - samples/sec: 43.88\n",
            "2020-05-14 14:31:49,170 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:31:49,171 EPOCH 19 done: loss 3.9923 - lr 0.0500\n",
            "2020-05-14 14:31:51,021 DEV : loss 3.606685161590576 - score 0.6481\n",
            "2020-05-14 14:31:51,026 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:32:03,861 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:32:07,268 epoch 20 - iter 4/46 - loss 4.03926623 - samples/sec: 37.59\n",
            "2020-05-14 14:32:10,245 epoch 20 - iter 8/46 - loss 3.68400085 - samples/sec: 43.27\n",
            "2020-05-14 14:32:13,894 epoch 20 - iter 12/46 - loss 3.91676615 - samples/sec: 35.34\n",
            "2020-05-14 14:32:17,741 epoch 20 - iter 16/46 - loss 3.84324215 - samples/sec: 33.46\n",
            "2020-05-14 14:32:21,370 epoch 20 - iter 20/46 - loss 3.78378578 - samples/sec: 35.52\n",
            "2020-05-14 14:32:24,931 epoch 20 - iter 24/46 - loss 3.86466022 - samples/sec: 36.12\n",
            "2020-05-14 14:32:28,497 epoch 20 - iter 28/46 - loss 3.97383074 - samples/sec: 36.10\n",
            "2020-05-14 14:32:32,604 epoch 20 - iter 32/46 - loss 3.98925094 - samples/sec: 31.38\n",
            "2020-05-14 14:32:35,585 epoch 20 - iter 36/46 - loss 4.09549250 - samples/sec: 43.29\n",
            "2020-05-14 14:32:39,184 epoch 20 - iter 40/46 - loss 4.05111918 - samples/sec: 35.73\n",
            "2020-05-14 14:32:42,924 epoch 20 - iter 44/46 - loss 3.99733657 - samples/sec: 34.40\n",
            "2020-05-14 14:32:44,760 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:32:44,761 EPOCH 20 done: loss 3.9139 - lr 0.0500\n",
            "2020-05-14 14:32:46,633 DEV : loss 3.6919493675231934 - score 0.6583\n",
            "2020-05-14 14:32:46,641 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 14:32:59,652 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:33:03,159 epoch 21 - iter 4/46 - loss 4.30195367 - samples/sec: 36.53\n",
            "2020-05-14 14:33:06,113 epoch 21 - iter 8/46 - loss 3.90991455 - samples/sec: 43.64\n",
            "2020-05-14 14:33:10,698 epoch 21 - iter 12/46 - loss 4.08585521 - samples/sec: 28.03\n",
            "2020-05-14 14:33:15,411 epoch 21 - iter 16/46 - loss 4.16296056 - samples/sec: 27.26\n",
            "2020-05-14 14:33:19,232 epoch 21 - iter 20/46 - loss 4.12970284 - samples/sec: 33.67\n",
            "2020-05-14 14:33:21,504 epoch 21 - iter 24/46 - loss 3.82265424 - samples/sec: 56.79\n",
            "2020-05-14 14:33:25,422 epoch 21 - iter 28/46 - loss 3.83081453 - samples/sec: 32.84\n",
            "2020-05-14 14:33:29,934 epoch 21 - iter 32/46 - loss 3.71351317 - samples/sec: 28.50\n",
            "2020-05-14 14:33:33,454 epoch 21 - iter 36/46 - loss 3.70500080 - samples/sec: 36.55\n",
            "2020-05-14 14:33:36,693 epoch 21 - iter 40/46 - loss 3.73451817 - samples/sec: 39.73\n",
            "2020-05-14 14:33:39,627 epoch 21 - iter 44/46 - loss 3.86146170 - samples/sec: 43.94\n",
            "2020-05-14 14:33:41,237 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:33:41,238 EPOCH 21 done: loss 3.8933 - lr 0.0500\n",
            "2020-05-14 14:33:43,091 DEV : loss 3.571469306945801 - score 0.668\n",
            "2020-05-14 14:33:43,097 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:34:25,083 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:34:30,785 epoch 22 - iter 4/46 - loss 4.16947436 - samples/sec: 34.69\n",
            "2020-05-14 14:34:35,350 epoch 22 - iter 8/46 - loss 3.38406810 - samples/sec: 28.15\n",
            "2020-05-14 14:34:39,579 epoch 22 - iter 12/46 - loss 3.80783411 - samples/sec: 30.39\n",
            "2020-05-14 14:34:43,189 epoch 22 - iter 16/46 - loss 4.04286793 - samples/sec: 35.68\n",
            "2020-05-14 14:34:46,304 epoch 22 - iter 20/46 - loss 4.16611228 - samples/sec: 41.33\n",
            "2020-05-14 14:34:49,505 epoch 22 - iter 24/46 - loss 4.11568179 - samples/sec: 40.24\n",
            "2020-05-14 14:34:53,042 epoch 22 - iter 28/46 - loss 4.07445232 - samples/sec: 36.48\n",
            "2020-05-14 14:34:55,870 epoch 22 - iter 32/46 - loss 3.98050257 - samples/sec: 45.55\n",
            "2020-05-14 14:34:59,793 epoch 22 - iter 36/46 - loss 4.01400586 - samples/sec: 32.79\n",
            "2020-05-14 14:35:03,383 epoch 22 - iter 40/46 - loss 3.99432057 - samples/sec: 35.84\n",
            "2020-05-14 14:35:07,708 epoch 22 - iter 44/46 - loss 3.95985593 - samples/sec: 29.72\n",
            "2020-05-14 14:35:08,974 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:35:08,975 EPOCH 22 done: loss 3.8522 - lr 0.0500\n",
            "2020-05-14 14:35:10,860 DEV : loss 3.5724105834960938 - score 0.6708\n",
            "2020-05-14 14:35:10,865 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:35:52,764 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:35:56,888 epoch 23 - iter 4/46 - loss 3.35051477 - samples/sec: 32.83\n",
            "2020-05-14 14:35:59,970 epoch 23 - iter 8/46 - loss 3.08479258 - samples/sec: 41.77\n",
            "2020-05-14 14:36:03,889 epoch 23 - iter 12/46 - loss 3.14843803 - samples/sec: 32.83\n",
            "2020-05-14 14:36:08,576 epoch 23 - iter 16/46 - loss 3.51858432 - samples/sec: 27.43\n",
            "2020-05-14 14:36:12,103 epoch 23 - iter 20/46 - loss 3.44575766 - samples/sec: 36.47\n",
            "2020-05-14 14:36:16,001 epoch 23 - iter 24/46 - loss 3.78790120 - samples/sec: 33.01\n",
            "2020-05-14 14:36:19,064 epoch 23 - iter 28/46 - loss 3.62905960 - samples/sec: 42.05\n",
            "2020-05-14 14:36:22,834 epoch 23 - iter 32/46 - loss 3.72489547 - samples/sec: 34.11\n",
            "2020-05-14 14:36:25,893 epoch 23 - iter 36/46 - loss 3.70878462 - samples/sec: 42.08\n",
            "2020-05-14 14:36:29,910 epoch 23 - iter 40/46 - loss 3.86529239 - samples/sec: 32.02\n",
            "2020-05-14 14:36:33,316 epoch 23 - iter 44/46 - loss 3.84511023 - samples/sec: 37.81\n",
            "2020-05-14 14:36:34,971 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:36:34,972 EPOCH 23 done: loss 3.8861 - lr 0.0500\n",
            "2020-05-14 14:36:36,954 DEV : loss 3.4870777130126953 - score 0.6638\n",
            "2020-05-14 14:36:36,962 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:36:49,931 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:36:53,239 epoch 24 - iter 4/46 - loss 4.47378010 - samples/sec: 38.73\n",
            "2020-05-14 14:36:57,322 epoch 24 - iter 8/46 - loss 4.34817970 - samples/sec: 31.50\n",
            "2020-05-14 14:37:00,933 epoch 24 - iter 12/46 - loss 4.03895958 - samples/sec: 35.63\n",
            "2020-05-14 14:37:04,836 epoch 24 - iter 16/46 - loss 3.90628192 - samples/sec: 32.96\n",
            "2020-05-14 14:37:07,932 epoch 24 - iter 20/46 - loss 3.81170309 - samples/sec: 41.59\n",
            "2020-05-14 14:37:11,571 epoch 24 - iter 24/46 - loss 3.76323494 - samples/sec: 35.38\n",
            "2020-05-14 14:37:14,967 epoch 24 - iter 28/46 - loss 3.92184496 - samples/sec: 37.91\n",
            "2020-05-14 14:37:19,125 epoch 24 - iter 32/46 - loss 3.94703856 - samples/sec: 30.94\n",
            "2020-05-14 14:37:22,856 epoch 24 - iter 36/46 - loss 3.86073965 - samples/sec: 34.48\n",
            "2020-05-14 14:37:26,406 epoch 24 - iter 40/46 - loss 3.98682413 - samples/sec: 36.23\n",
            "2020-05-14 14:37:29,573 epoch 24 - iter 44/46 - loss 3.82147162 - samples/sec: 40.67\n",
            "2020-05-14 14:37:31,029 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:37:31,030 EPOCH 24 done: loss 3.8388 - lr 0.0500\n",
            "2020-05-14 14:37:32,979 DEV : loss 3.4998767375946045 - score 0.6694\n",
            "2020-05-14 14:37:32,984 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 14:37:46,150 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:37:50,117 epoch 25 - iter 4/46 - loss 3.20899189 - samples/sec: 32.28\n",
            "2020-05-14 14:37:53,958 epoch 25 - iter 8/46 - loss 4.02554266 - samples/sec: 33.54\n",
            "2020-05-14 14:37:58,089 epoch 25 - iter 12/46 - loss 4.27770568 - samples/sec: 31.12\n",
            "2020-05-14 14:38:01,441 epoch 25 - iter 16/46 - loss 4.01530122 - samples/sec: 38.40\n",
            "2020-05-14 14:38:05,007 epoch 25 - iter 20/46 - loss 4.02600468 - samples/sec: 36.08\n",
            "2020-05-14 14:38:09,058 epoch 25 - iter 24/46 - loss 3.92684650 - samples/sec: 31.76\n",
            "2020-05-14 14:38:12,165 epoch 25 - iter 28/46 - loss 4.00580405 - samples/sec: 41.47\n",
            "2020-05-14 14:38:16,716 epoch 25 - iter 32/46 - loss 3.99031057 - samples/sec: 28.24\n",
            "2020-05-14 14:38:21,425 epoch 25 - iter 36/46 - loss 3.93956037 - samples/sec: 27.30\n",
            "2020-05-14 14:38:24,314 epoch 25 - iter 40/46 - loss 3.84311154 - samples/sec: 44.63\n",
            "2020-05-14 14:38:26,937 epoch 25 - iter 44/46 - loss 3.86241757 - samples/sec: 49.13\n",
            "2020-05-14 14:38:28,437 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:38:28,438 EPOCH 25 done: loss 3.7965 - lr 0.0500\n",
            "2020-05-14 14:38:30,378 DEV : loss 3.4436984062194824 - score 0.6872\n",
            "2020-05-14 14:38:30,387 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:39:14,167 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:39:18,616 epoch 26 - iter 4/46 - loss 3.46885449 - samples/sec: 34.29\n",
            "2020-05-14 14:39:21,856 epoch 26 - iter 8/46 - loss 3.90726092 - samples/sec: 39.76\n",
            "2020-05-14 14:39:24,855 epoch 26 - iter 12/46 - loss 3.72482493 - samples/sec: 43.00\n",
            "2020-05-14 14:39:28,323 epoch 26 - iter 16/46 - loss 3.55814230 - samples/sec: 37.13\n",
            "2020-05-14 14:39:30,777 epoch 26 - iter 20/46 - loss 3.52917233 - samples/sec: 52.60\n",
            "2020-05-14 14:39:34,673 epoch 26 - iter 24/46 - loss 3.73497868 - samples/sec: 33.03\n",
            "2020-05-14 14:39:38,493 epoch 26 - iter 28/46 - loss 3.74016750 - samples/sec: 33.69\n",
            "2020-05-14 14:39:42,198 epoch 26 - iter 32/46 - loss 3.71759807 - samples/sec: 34.71\n",
            "2020-05-14 14:39:46,905 epoch 26 - iter 36/46 - loss 3.64574820 - samples/sec: 27.30\n",
            "2020-05-14 14:39:50,871 epoch 26 - iter 40/46 - loss 3.57912973 - samples/sec: 32.43\n",
            "2020-05-14 14:39:54,271 epoch 26 - iter 44/46 - loss 3.74712332 - samples/sec: 37.91\n",
            "2020-05-14 14:39:55,776 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:39:55,777 EPOCH 26 done: loss 3.7237 - lr 0.0500\n",
            "2020-05-14 14:39:57,705 DEV : loss 3.487934112548828 - score 0.6829\n",
            "2020-05-14 14:39:57,711 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:40:10,894 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:40:14,164 epoch 27 - iter 4/46 - loss 4.43901253 - samples/sec: 39.17\n",
            "2020-05-14 14:40:17,492 epoch 27 - iter 8/46 - loss 3.93242258 - samples/sec: 38.70\n",
            "2020-05-14 14:40:20,867 epoch 27 - iter 12/46 - loss 3.65046358 - samples/sec: 38.17\n",
            "2020-05-14 14:40:25,358 epoch 27 - iter 16/46 - loss 4.05668688 - samples/sec: 28.64\n",
            "2020-05-14 14:40:28,930 epoch 27 - iter 20/46 - loss 4.09741508 - samples/sec: 36.07\n",
            "2020-05-14 14:40:31,933 epoch 27 - iter 24/46 - loss 3.93043747 - samples/sec: 42.90\n",
            "2020-05-14 14:40:35,605 epoch 27 - iter 28/46 - loss 3.86633896 - samples/sec: 35.06\n",
            "2020-05-14 14:40:39,903 epoch 27 - iter 32/46 - loss 3.83270162 - samples/sec: 29.92\n",
            "2020-05-14 14:40:43,272 epoch 27 - iter 36/46 - loss 3.74873981 - samples/sec: 38.23\n",
            "2020-05-14 14:40:47,063 epoch 27 - iter 40/46 - loss 3.72835829 - samples/sec: 33.97\n",
            "2020-05-14 14:40:51,481 epoch 27 - iter 44/46 - loss 3.83105969 - samples/sec: 29.10\n",
            "2020-05-14 14:40:53,034 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:40:53,036 EPOCH 27 done: loss 3.7744 - lr 0.0500\n",
            "2020-05-14 14:40:55,012 DEV : loss 3.6303930282592773 - score 0.6667\n",
            "2020-05-14 14:40:55,021 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 14:41:08,172 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:41:12,303 epoch 28 - iter 4/46 - loss 2.88181508 - samples/sec: 31.02\n",
            "2020-05-14 14:41:17,158 epoch 28 - iter 8/46 - loss 3.24184051 - samples/sec: 26.48\n",
            "2020-05-14 14:41:20,290 epoch 28 - iter 12/46 - loss 3.44068219 - samples/sec: 41.19\n",
            "2020-05-14 14:41:22,789 epoch 28 - iter 16/46 - loss 3.24787227 - samples/sec: 51.63\n",
            "2020-05-14 14:41:26,510 epoch 28 - iter 20/46 - loss 3.58508828 - samples/sec: 34.59\n",
            "2020-05-14 14:41:30,168 epoch 28 - iter 24/46 - loss 3.76990519 - samples/sec: 35.21\n",
            "2020-05-14 14:41:33,347 epoch 28 - iter 28/46 - loss 3.84594373 - samples/sec: 40.50\n",
            "2020-05-14 14:41:36,772 epoch 28 - iter 32/46 - loss 3.75920668 - samples/sec: 37.59\n",
            "2020-05-14 14:41:40,440 epoch 28 - iter 36/46 - loss 3.78142678 - samples/sec: 35.12\n",
            "2020-05-14 14:41:44,195 epoch 28 - iter 40/46 - loss 3.72766354 - samples/sec: 34.24\n",
            "2020-05-14 14:41:47,264 epoch 28 - iter 44/46 - loss 3.71887693 - samples/sec: 41.98\n",
            "2020-05-14 14:41:48,624 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:41:48,625 EPOCH 28 done: loss 3.6486 - lr 0.0500\n",
            "2020-05-14 14:41:50,583 DEV : loss 3.571383476257324 - score 0.6814\n",
            "2020-05-14 14:41:50,591 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 14:42:03,800 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:42:07,129 epoch 29 - iter 4/46 - loss 3.90987247 - samples/sec: 38.47\n",
            "2020-05-14 14:42:09,785 epoch 29 - iter 8/46 - loss 3.54234342 - samples/sec: 48.54\n",
            "2020-05-14 14:42:13,621 epoch 29 - iter 12/46 - loss 3.53260093 - samples/sec: 33.53\n",
            "2020-05-14 14:42:18,398 epoch 29 - iter 16/46 - loss 3.69243018 - samples/sec: 26.90\n",
            "2020-05-14 14:42:21,461 epoch 29 - iter 20/46 - loss 3.81256139 - samples/sec: 42.06\n",
            "2020-05-14 14:42:26,334 epoch 29 - iter 24/46 - loss 3.68026957 - samples/sec: 26.38\n",
            "2020-05-14 14:42:29,445 epoch 29 - iter 28/46 - loss 3.69963275 - samples/sec: 41.38\n",
            "2020-05-14 14:42:32,388 epoch 29 - iter 32/46 - loss 3.79534854 - samples/sec: 43.77\n",
            "2020-05-14 14:42:34,526 epoch 29 - iter 36/46 - loss 3.74859797 - samples/sec: 60.43\n",
            "2020-05-14 14:42:37,626 epoch 29 - iter 40/46 - loss 3.69671033 - samples/sec: 41.57\n",
            "2020-05-14 14:42:41,813 epoch 29 - iter 44/46 - loss 3.66109268 - samples/sec: 30.72\n",
            "2020-05-14 14:42:43,872 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:42:43,873 EPOCH 29 done: loss 3.6946 - lr 0.0500\n",
            "2020-05-14 14:42:45,800 DEV : loss 3.5588834285736084 - score 0.6639\n",
            "Epoch    29: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-05-14 14:42:45,809 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 14:42:58,963 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:43:02,445 epoch 30 - iter 4/46 - loss 4.36242259 - samples/sec: 36.79\n",
            "2020-05-14 14:43:07,148 epoch 30 - iter 8/46 - loss 4.80946678 - samples/sec: 27.34\n",
            "2020-05-14 14:43:10,796 epoch 30 - iter 12/46 - loss 4.14925686 - samples/sec: 35.25\n",
            "2020-05-14 14:43:13,568 epoch 30 - iter 16/46 - loss 3.95649014 - samples/sec: 46.51\n",
            "2020-05-14 14:43:15,718 epoch 30 - iter 20/46 - loss 3.89481394 - samples/sec: 60.07\n",
            "2020-05-14 14:43:19,305 epoch 30 - iter 24/46 - loss 3.96957629 - samples/sec: 35.89\n",
            "2020-05-14 14:43:21,915 epoch 30 - iter 28/46 - loss 3.74562842 - samples/sec: 49.48\n",
            "2020-05-14 14:43:26,296 epoch 30 - iter 32/46 - loss 3.63204756 - samples/sec: 29.34\n",
            "2020-05-14 14:43:31,024 epoch 30 - iter 36/46 - loss 3.70149593 - samples/sec: 27.17\n",
            "2020-05-14 14:43:34,234 epoch 30 - iter 40/46 - loss 3.68005046 - samples/sec: 40.11\n",
            "2020-05-14 14:43:38,080 epoch 30 - iter 44/46 - loss 3.64714516 - samples/sec: 33.47\n",
            "2020-05-14 14:43:39,669 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:43:39,670 EPOCH 30 done: loss 3.6182 - lr 0.0250\n",
            "2020-05-14 14:43:41,551 DEV : loss 3.4859023094177246 - score 0.6857\n",
            "2020-05-14 14:43:41,560 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:43:54,740 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:43:58,352 epoch 31 - iter 4/46 - loss 3.42703974 - samples/sec: 35.47\n",
            "2020-05-14 14:44:02,869 epoch 31 - iter 8/46 - loss 3.73482370 - samples/sec: 28.44\n",
            "2020-05-14 14:44:06,903 epoch 31 - iter 12/46 - loss 3.98880247 - samples/sec: 31.92\n",
            "2020-05-14 14:44:09,736 epoch 31 - iter 16/46 - loss 3.66192693 - samples/sec: 45.50\n",
            "2020-05-14 14:44:13,935 epoch 31 - iter 20/46 - loss 3.44165139 - samples/sec: 30.62\n",
            "2020-05-14 14:44:17,831 epoch 31 - iter 24/46 - loss 3.43963570 - samples/sec: 33.02\n",
            "2020-05-14 14:44:21,659 epoch 31 - iter 28/46 - loss 3.70476824 - samples/sec: 33.61\n",
            "2020-05-14 14:44:25,228 epoch 31 - iter 32/46 - loss 3.74417723 - samples/sec: 36.09\n",
            "2020-05-14 14:44:28,402 epoch 31 - iter 36/46 - loss 3.69761209 - samples/sec: 40.52\n",
            "2020-05-14 14:44:31,640 epoch 31 - iter 40/46 - loss 3.70575716 - samples/sec: 39.77\n",
            "2020-05-14 14:44:34,401 epoch 31 - iter 44/46 - loss 3.57351940 - samples/sec: 46.71\n",
            "2020-05-14 14:44:36,039 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:44:36,041 EPOCH 31 done: loss 3.5367 - lr 0.0250\n",
            "2020-05-14 14:44:37,979 DEV : loss 3.55424165725708 - score 0.6802\n",
            "2020-05-14 14:44:37,988 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 14:44:51,147 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:44:55,410 epoch 32 - iter 4/46 - loss 3.97145426 - samples/sec: 30.08\n",
            "2020-05-14 14:44:59,525 epoch 32 - iter 8/46 - loss 3.50036630 - samples/sec: 31.23\n",
            "2020-05-14 14:45:03,404 epoch 32 - iter 12/46 - loss 3.39535062 - samples/sec: 33.15\n",
            "2020-05-14 14:45:06,373 epoch 32 - iter 16/46 - loss 3.60658701 - samples/sec: 43.42\n",
            "2020-05-14 14:45:09,650 epoch 32 - iter 20/46 - loss 3.66093236 - samples/sec: 39.28\n",
            "2020-05-14 14:45:12,581 epoch 32 - iter 24/46 - loss 3.71666660 - samples/sec: 44.05\n",
            "2020-05-14 14:45:17,235 epoch 32 - iter 28/46 - loss 3.65462146 - samples/sec: 27.60\n",
            "2020-05-14 14:45:20,402 epoch 32 - iter 32/46 - loss 3.59549772 - samples/sec: 40.64\n",
            "2020-05-14 14:45:23,434 epoch 32 - iter 36/46 - loss 3.57279580 - samples/sec: 42.50\n",
            "2020-05-14 14:45:26,934 epoch 32 - iter 40/46 - loss 3.46381333 - samples/sec: 36.77\n",
            "2020-05-14 14:45:29,476 epoch 32 - iter 44/46 - loss 3.45622621 - samples/sec: 50.75\n",
            "2020-05-14 14:45:31,758 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:45:31,759 EPOCH 32 done: loss 3.5212 - lr 0.0250\n",
            "2020-05-14 14:45:33,706 DEV : loss 3.4005067348480225 - score 0.6817\n",
            "2020-05-14 14:45:33,711 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 14:45:46,940 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:45:50,433 epoch 33 - iter 4/46 - loss 3.10179311 - samples/sec: 36.68\n",
            "2020-05-14 14:45:54,177 epoch 33 - iter 8/46 - loss 3.46941233 - samples/sec: 34.37\n",
            "2020-05-14 14:45:57,401 epoch 33 - iter 12/46 - loss 3.17160519 - samples/sec: 39.94\n",
            "2020-05-14 14:46:00,494 epoch 33 - iter 16/46 - loss 3.27410892 - samples/sec: 41.62\n",
            "2020-05-14 14:46:03,819 epoch 33 - iter 20/46 - loss 3.29729491 - samples/sec: 38.71\n",
            "2020-05-14 14:46:07,755 epoch 33 - iter 24/46 - loss 3.36197596 - samples/sec: 32.69\n",
            "2020-05-14 14:46:11,706 epoch 33 - iter 28/46 - loss 3.24758564 - samples/sec: 32.55\n",
            "2020-05-14 14:46:15,958 epoch 33 - iter 32/46 - loss 3.24498303 - samples/sec: 30.23\n",
            "2020-05-14 14:46:19,995 epoch 33 - iter 36/46 - loss 3.38335196 - samples/sec: 31.87\n",
            "2020-05-14 14:46:23,206 epoch 33 - iter 40/46 - loss 3.57099938 - samples/sec: 40.15\n",
            "2020-05-14 14:46:26,744 epoch 33 - iter 44/46 - loss 3.53242332 - samples/sec: 36.38\n",
            "2020-05-14 14:46:28,297 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:46:28,299 EPOCH 33 done: loss 3.5207 - lr 0.0250\n",
            "2020-05-14 14:46:30,208 DEV : loss 3.4339938163757324 - score 0.6805\n",
            "Epoch    33: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-05-14 14:46:30,217 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 14:46:43,375 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:46:46,432 epoch 34 - iter 4/46 - loss 2.41754353 - samples/sec: 41.92\n",
            "2020-05-14 14:46:50,076 epoch 34 - iter 8/46 - loss 2.66278526 - samples/sec: 35.32\n",
            "2020-05-14 14:46:53,824 epoch 34 - iter 12/46 - loss 2.73304874 - samples/sec: 34.32\n",
            "2020-05-14 14:46:58,295 epoch 34 - iter 16/46 - loss 3.18106349 - samples/sec: 28.76\n",
            "2020-05-14 14:47:01,496 epoch 34 - iter 20/46 - loss 3.28674302 - samples/sec: 40.21\n",
            "2020-05-14 14:47:04,392 epoch 34 - iter 24/46 - loss 3.23246069 - samples/sec: 44.46\n",
            "2020-05-14 14:47:08,329 epoch 34 - iter 28/46 - loss 3.28183163 - samples/sec: 32.68\n",
            "2020-05-14 14:47:12,040 epoch 34 - iter 32/46 - loss 3.27093113 - samples/sec: 34.69\n",
            "2020-05-14 14:47:14,885 epoch 34 - iter 36/46 - loss 3.24756879 - samples/sec: 45.31\n",
            "2020-05-14 14:47:18,080 epoch 34 - iter 40/46 - loss 3.33359958 - samples/sec: 40.31\n",
            "2020-05-14 14:47:21,454 epoch 34 - iter 44/46 - loss 3.47734663 - samples/sec: 38.16\n",
            "2020-05-14 14:47:23,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:47:23,735 EPOCH 34 done: loss 3.4508 - lr 0.0125\n",
            "2020-05-14 14:47:25,658 DEV : loss 3.4047460556030273 - score 0.6898\n",
            "2020-05-14 14:47:25,664 BAD EPOCHS (no improvement): 0\n",
            "2020-05-14 14:48:07,605 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:48:10,735 epoch 35 - iter 4/46 - loss 3.06859601 - samples/sec: 45.58\n",
            "2020-05-14 14:48:14,931 epoch 35 - iter 8/46 - loss 3.52792037 - samples/sec: 33.13\n",
            "2020-05-14 14:48:17,906 epoch 35 - iter 12/46 - loss 3.48598127 - samples/sec: 43.31\n",
            "2020-05-14 14:48:22,127 epoch 35 - iter 16/46 - loss 3.63266405 - samples/sec: 30.48\n",
            "2020-05-14 14:48:24,896 epoch 35 - iter 20/46 - loss 3.66369425 - samples/sec: 46.52\n",
            "2020-05-14 14:48:27,954 epoch 35 - iter 24/46 - loss 3.61530870 - samples/sec: 42.15\n",
            "2020-05-14 14:48:32,615 epoch 35 - iter 28/46 - loss 3.71035815 - samples/sec: 27.56\n",
            "2020-05-14 14:48:35,751 epoch 35 - iter 32/46 - loss 3.62413808 - samples/sec: 41.07\n",
            "2020-05-14 14:48:39,894 epoch 35 - iter 36/46 - loss 3.63431949 - samples/sec: 31.06\n",
            "2020-05-14 14:48:44,118 epoch 35 - iter 40/46 - loss 3.58044580 - samples/sec: 30.47\n",
            "2020-05-14 14:48:47,446 epoch 35 - iter 44/46 - loss 3.59023470 - samples/sec: 38.65\n",
            "2020-05-14 14:48:48,856 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:48:48,857 EPOCH 35 done: loss 3.5529 - lr 0.0125\n",
            "2020-05-14 14:48:50,760 DEV : loss 3.4450225830078125 - score 0.6735\n",
            "2020-05-14 14:48:50,769 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:49:03,749 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:49:07,476 epoch 36 - iter 4/46 - loss 3.91598672 - samples/sec: 34.36\n",
            "2020-05-14 14:49:09,409 epoch 36 - iter 8/46 - loss 3.17642391 - samples/sec: 66.80\n",
            "2020-05-14 14:49:13,536 epoch 36 - iter 12/46 - loss 3.16578195 - samples/sec: 31.16\n",
            "2020-05-14 14:49:17,202 epoch 36 - iter 16/46 - loss 3.30259347 - samples/sec: 35.08\n",
            "2020-05-14 14:49:20,595 epoch 36 - iter 20/46 - loss 3.41138288 - samples/sec: 37.95\n",
            "2020-05-14 14:49:24,417 epoch 36 - iter 24/46 - loss 3.47142366 - samples/sec: 33.65\n",
            "2020-05-14 14:49:28,037 epoch 36 - iter 28/46 - loss 3.34688074 - samples/sec: 35.60\n",
            "2020-05-14 14:49:32,389 epoch 36 - iter 32/46 - loss 3.41655244 - samples/sec: 29.54\n",
            "2020-05-14 14:49:36,340 epoch 36 - iter 36/46 - loss 3.36146664 - samples/sec: 32.55\n",
            "2020-05-14 14:49:40,363 epoch 36 - iter 40/46 - loss 3.37523355 - samples/sec: 31.98\n",
            "2020-05-14 14:49:44,478 epoch 36 - iter 44/46 - loss 3.42460684 - samples/sec: 31.24\n",
            "2020-05-14 14:49:45,415 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:49:45,418 EPOCH 36 done: loss 3.3850 - lr 0.0125\n",
            "2020-05-14 14:49:47,420 DEV : loss 3.4305648803710938 - score 0.6776\n",
            "2020-05-14 14:49:47,426 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 14:50:00,609 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:50:03,892 epoch 37 - iter 4/46 - loss 3.64656395 - samples/sec: 39.04\n",
            "2020-05-14 14:50:06,405 epoch 37 - iter 8/46 - loss 3.08320928 - samples/sec: 51.30\n",
            "2020-05-14 14:50:09,959 epoch 37 - iter 12/46 - loss 3.29934454 - samples/sec: 36.22\n",
            "2020-05-14 14:50:13,372 epoch 37 - iter 16/46 - loss 3.53925201 - samples/sec: 37.77\n",
            "2020-05-14 14:50:17,060 epoch 37 - iter 20/46 - loss 3.75975989 - samples/sec: 34.93\n",
            "2020-05-14 14:50:19,530 epoch 37 - iter 24/46 - loss 3.59964683 - samples/sec: 52.30\n",
            "2020-05-14 14:50:22,984 epoch 37 - iter 28/46 - loss 3.56253666 - samples/sec: 37.29\n",
            "2020-05-14 14:50:26,282 epoch 37 - iter 32/46 - loss 3.42754255 - samples/sec: 39.07\n",
            "2020-05-14 14:50:30,956 epoch 37 - iter 36/46 - loss 3.44576558 - samples/sec: 27.52\n",
            "2020-05-14 14:50:35,504 epoch 37 - iter 40/46 - loss 3.45135638 - samples/sec: 28.27\n",
            "2020-05-14 14:50:39,712 epoch 37 - iter 44/46 - loss 3.50911738 - samples/sec: 30.56\n",
            "2020-05-14 14:50:41,065 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:50:41,067 EPOCH 37 done: loss 3.4509 - lr 0.0125\n",
            "2020-05-14 14:50:42,999 DEV : loss 3.4301929473876953 - score 0.6886\n",
            "2020-05-14 14:50:43,008 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 14:50:56,318 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:51:01,615 epoch 38 - iter 4/46 - loss 4.68008476 - samples/sec: 24.18\n",
            "2020-05-14 14:51:05,192 epoch 38 - iter 8/46 - loss 3.54468480 - samples/sec: 35.95\n",
            "2020-05-14 14:51:09,286 epoch 38 - iter 12/46 - loss 3.67179515 - samples/sec: 31.39\n",
            "2020-05-14 14:51:12,012 epoch 38 - iter 16/46 - loss 3.50009713 - samples/sec: 47.28\n",
            "2020-05-14 14:51:15,307 epoch 38 - iter 20/46 - loss 3.31690990 - samples/sec: 39.10\n",
            "2020-05-14 14:51:18,457 epoch 38 - iter 24/46 - loss 3.21914064 - samples/sec: 40.89\n",
            "2020-05-14 14:51:21,337 epoch 38 - iter 28/46 - loss 3.24576671 - samples/sec: 44.73\n",
            "2020-05-14 14:51:24,077 epoch 38 - iter 32/46 - loss 3.33928609 - samples/sec: 47.00\n",
            "2020-05-14 14:51:27,311 epoch 38 - iter 36/46 - loss 3.43763962 - samples/sec: 39.82\n",
            "2020-05-14 14:51:31,487 epoch 38 - iter 40/46 - loss 3.55722987 - samples/sec: 30.79\n",
            "2020-05-14 14:51:35,531 epoch 38 - iter 44/46 - loss 3.47605838 - samples/sec: 31.80\n",
            "2020-05-14 14:51:36,902 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:51:36,903 EPOCH 38 done: loss 3.4678 - lr 0.0125\n",
            "2020-05-14 14:51:38,833 DEV : loss 3.4166038036346436 - score 0.6857\n",
            "Epoch    38: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-05-14 14:51:38,839 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 14:51:52,111 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:51:55,596 epoch 39 - iter 4/46 - loss 3.60844278 - samples/sec: 36.75\n",
            "2020-05-14 14:51:59,240 epoch 39 - iter 8/46 - loss 3.42536759 - samples/sec: 35.31\n",
            "2020-05-14 14:52:02,760 epoch 39 - iter 12/46 - loss 3.23664077 - samples/sec: 36.55\n",
            "2020-05-14 14:52:06,260 epoch 39 - iter 16/46 - loss 3.70687473 - samples/sec: 36.77\n",
            "2020-05-14 14:52:10,596 epoch 39 - iter 20/46 - loss 3.65226386 - samples/sec: 29.65\n",
            "2020-05-14 14:52:14,070 epoch 39 - iter 24/46 - loss 3.62483572 - samples/sec: 37.03\n",
            "2020-05-14 14:52:18,665 epoch 39 - iter 28/46 - loss 3.55120615 - samples/sec: 27.97\n",
            "2020-05-14 14:52:22,824 epoch 39 - iter 32/46 - loss 3.43797545 - samples/sec: 30.92\n",
            "2020-05-14 14:52:25,838 epoch 39 - iter 36/46 - loss 3.54989291 - samples/sec: 42.75\n",
            "2020-05-14 14:52:29,043 epoch 39 - iter 40/46 - loss 3.46768863 - samples/sec: 40.19\n",
            "2020-05-14 14:52:31,765 epoch 39 - iter 44/46 - loss 3.43401239 - samples/sec: 47.34\n",
            "2020-05-14 14:52:33,739 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:52:33,740 EPOCH 39 done: loss 3.4563 - lr 0.0063\n",
            "2020-05-14 14:52:35,691 DEV : loss 3.4083547592163086 - score 0.6844\n",
            "2020-05-14 14:52:35,697 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:52:49,202 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:52:53,822 epoch 40 - iter 4/46 - loss 4.08257318 - samples/sec: 27.72\n",
            "2020-05-14 14:52:57,125 epoch 40 - iter 8/46 - loss 3.42657441 - samples/sec: 38.99\n",
            "2020-05-14 14:53:01,229 epoch 40 - iter 12/46 - loss 3.80293061 - samples/sec: 31.33\n",
            "2020-05-14 14:53:05,093 epoch 40 - iter 16/46 - loss 3.78492054 - samples/sec: 33.27\n",
            "2020-05-14 14:53:09,392 epoch 40 - iter 20/46 - loss 3.88717768 - samples/sec: 29.90\n",
            "2020-05-14 14:53:12,367 epoch 40 - iter 24/46 - loss 3.82960856 - samples/sec: 43.28\n",
            "2020-05-14 14:53:16,304 epoch 40 - iter 28/46 - loss 3.79991551 - samples/sec: 32.69\n",
            "2020-05-14 14:53:18,797 epoch 40 - iter 32/46 - loss 3.67194738 - samples/sec: 51.71\n",
            "2020-05-14 14:53:22,262 epoch 40 - iter 36/46 - loss 3.51536852 - samples/sec: 37.17\n",
            "2020-05-14 14:53:25,348 epoch 40 - iter 40/46 - loss 3.50203823 - samples/sec: 41.74\n",
            "2020-05-14 14:53:29,460 epoch 40 - iter 44/46 - loss 3.42839411 - samples/sec: 31.28\n",
            "2020-05-14 14:53:31,038 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:53:31,039 EPOCH 40 done: loss 3.3647 - lr 0.0063\n",
            "2020-05-14 14:53:33,014 DEV : loss 3.4261531829833984 - score 0.6789\n",
            "2020-05-14 14:53:33,020 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 14:53:46,480 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:53:51,526 epoch 41 - iter 4/46 - loss 4.81370854 - samples/sec: 25.38\n",
            "2020-05-14 14:53:55,294 epoch 41 - iter 8/46 - loss 3.92797263 - samples/sec: 34.14\n",
            "2020-05-14 14:53:59,785 epoch 41 - iter 12/46 - loss 3.51189210 - samples/sec: 28.64\n",
            "2020-05-14 14:54:03,637 epoch 41 - iter 16/46 - loss 3.31041816 - samples/sec: 33.39\n",
            "2020-05-14 14:54:07,400 epoch 41 - iter 20/46 - loss 3.21846751 - samples/sec: 34.18\n",
            "2020-05-14 14:54:11,084 epoch 41 - iter 24/46 - loss 3.32297476 - samples/sec: 34.95\n",
            "2020-05-14 14:54:15,544 epoch 41 - iter 28/46 - loss 3.38104078 - samples/sec: 28.81\n",
            "2020-05-14 14:54:19,716 epoch 41 - iter 32/46 - loss 3.49333453 - samples/sec: 30.83\n",
            "2020-05-14 14:54:22,992 epoch 41 - iter 36/46 - loss 3.44155239 - samples/sec: 39.32\n",
            "2020-05-14 14:54:26,101 epoch 41 - iter 40/46 - loss 3.43181729 - samples/sec: 41.42\n",
            "2020-05-14 14:54:29,692 epoch 41 - iter 44/46 - loss 3.40260907 - samples/sec: 35.86\n",
            "2020-05-14 14:54:31,288 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:54:31,289 EPOCH 41 done: loss 3.3452 - lr 0.0063\n",
            "2020-05-14 14:54:33,221 DEV : loss 3.4070374965667725 - score 0.6789\n",
            "2020-05-14 14:54:33,227 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 14:54:46,782 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:54:50,962 epoch 42 - iter 4/46 - loss 3.12689000 - samples/sec: 30.64\n",
            "2020-05-14 14:54:54,306 epoch 42 - iter 8/46 - loss 3.25196239 - samples/sec: 38.50\n",
            "2020-05-14 14:54:57,327 epoch 42 - iter 12/46 - loss 3.21749696 - samples/sec: 42.63\n",
            "2020-05-14 14:55:00,084 epoch 42 - iter 16/46 - loss 2.97612566 - samples/sec: 46.76\n",
            "2020-05-14 14:55:03,910 epoch 42 - iter 20/46 - loss 2.99472730 - samples/sec: 33.60\n",
            "2020-05-14 14:55:08,507 epoch 42 - iter 24/46 - loss 3.11939719 - samples/sec: 27.97\n",
            "2020-05-14 14:55:12,564 epoch 42 - iter 28/46 - loss 3.50384427 - samples/sec: 31.72\n",
            "2020-05-14 14:55:16,464 epoch 42 - iter 32/46 - loss 3.48706260 - samples/sec: 32.97\n",
            "2020-05-14 14:55:20,996 epoch 42 - iter 36/46 - loss 3.60258458 - samples/sec: 28.36\n",
            "2020-05-14 14:55:23,740 epoch 42 - iter 40/46 - loss 3.56720508 - samples/sec: 46.97\n",
            "2020-05-14 14:55:26,637 epoch 42 - iter 44/46 - loss 3.41657335 - samples/sec: 44.52\n",
            "2020-05-14 14:55:28,044 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:55:28,046 EPOCH 42 done: loss 3.3970 - lr 0.0063\n",
            "2020-05-14 14:55:29,969 DEV : loss 3.4178683757781982 - score 0.6763\n",
            "Epoch    42: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-05-14 14:55:29,975 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 14:55:43,479 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:55:46,433 epoch 43 - iter 4/46 - loss 2.15968958 - samples/sec: 43.37\n",
            "2020-05-14 14:55:50,423 epoch 43 - iter 8/46 - loss 3.50667609 - samples/sec: 32.25\n",
            "2020-05-14 14:55:54,624 epoch 43 - iter 12/46 - loss 3.40476530 - samples/sec: 30.61\n",
            "2020-05-14 14:55:58,741 epoch 43 - iter 16/46 - loss 3.43698418 - samples/sec: 31.24\n",
            "2020-05-14 14:56:02,431 epoch 43 - iter 20/46 - loss 3.53488191 - samples/sec: 34.87\n",
            "2020-05-14 14:56:06,744 epoch 43 - iter 24/46 - loss 3.51191799 - samples/sec: 29.80\n",
            "2020-05-14 14:56:09,849 epoch 43 - iter 28/46 - loss 3.50989250 - samples/sec: 41.49\n",
            "2020-05-14 14:56:13,812 epoch 43 - iter 32/46 - loss 3.47166273 - samples/sec: 32.46\n",
            "2020-05-14 14:56:16,152 epoch 43 - iter 36/46 - loss 3.46829810 - samples/sec: 55.08\n",
            "2020-05-14 14:56:19,832 epoch 43 - iter 40/46 - loss 3.49243320 - samples/sec: 34.99\n",
            "2020-05-14 14:56:23,096 epoch 43 - iter 44/46 - loss 3.47543815 - samples/sec: 39.51\n",
            "2020-05-14 14:56:25,277 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:56:25,278 EPOCH 43 done: loss 3.4724 - lr 0.0031\n",
            "2020-05-14 14:56:27,196 DEV : loss 3.410134792327881 - score 0.6857\n",
            "2020-05-14 14:56:27,205 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 14:56:40,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:56:44,634 epoch 44 - iter 4/46 - loss 3.41982591 - samples/sec: 32.84\n",
            "2020-05-14 14:56:47,942 epoch 44 - iter 8/46 - loss 3.32082388 - samples/sec: 38.92\n",
            "2020-05-14 14:56:51,465 epoch 44 - iter 12/46 - loss 3.44804881 - samples/sec: 36.55\n",
            "2020-05-14 14:56:54,880 epoch 44 - iter 16/46 - loss 3.30776787 - samples/sec: 37.67\n",
            "2020-05-14 14:56:59,277 epoch 44 - iter 20/46 - loss 3.49807432 - samples/sec: 29.25\n",
            "2020-05-14 14:57:01,856 epoch 44 - iter 24/46 - loss 3.50635644 - samples/sec: 49.95\n",
            "2020-05-14 14:57:05,119 epoch 44 - iter 28/46 - loss 3.63632194 - samples/sec: 39.43\n",
            "2020-05-14 14:57:08,433 epoch 44 - iter 32/46 - loss 3.54847380 - samples/sec: 38.87\n",
            "2020-05-14 14:57:12,570 epoch 44 - iter 36/46 - loss 3.50775584 - samples/sec: 31.10\n",
            "2020-05-14 14:57:16,690 epoch 44 - iter 40/46 - loss 3.46898004 - samples/sec: 31.20\n",
            "2020-05-14 14:57:20,587 epoch 44 - iter 44/46 - loss 3.44242835 - samples/sec: 33.01\n",
            "2020-05-14 14:57:21,945 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:57:21,946 EPOCH 44 done: loss 3.3945 - lr 0.0031\n",
            "2020-05-14 14:57:23,904 DEV : loss 3.4032630920410156 - score 0.6803\n",
            "2020-05-14 14:57:23,910 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 14:57:37,412 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:57:40,399 epoch 45 - iter 4/46 - loss 2.75569597 - samples/sec: 42.92\n",
            "2020-05-14 14:57:44,480 epoch 45 - iter 8/46 - loss 3.09259503 - samples/sec: 31.52\n",
            "2020-05-14 14:57:47,494 epoch 45 - iter 12/46 - loss 3.01429257 - samples/sec: 42.74\n",
            "2020-05-14 14:57:50,377 epoch 45 - iter 16/46 - loss 3.13193772 - samples/sec: 44.72\n",
            "2020-05-14 14:57:53,831 epoch 45 - iter 20/46 - loss 3.22773516 - samples/sec: 37.25\n",
            "2020-05-14 14:57:56,739 epoch 45 - iter 24/46 - loss 2.97941872 - samples/sec: 44.29\n",
            "2020-05-14 14:58:01,029 epoch 45 - iter 28/46 - loss 3.01832857 - samples/sec: 29.98\n",
            "2020-05-14 14:58:04,442 epoch 45 - iter 32/46 - loss 3.08141593 - samples/sec: 37.70\n",
            "2020-05-14 14:58:08,337 epoch 45 - iter 36/46 - loss 3.14702063 - samples/sec: 33.03\n",
            "2020-05-14 14:58:13,424 epoch 45 - iter 40/46 - loss 3.26258220 - samples/sec: 25.26\n",
            "2020-05-14 14:58:17,240 epoch 45 - iter 44/46 - loss 3.27740725 - samples/sec: 33.70\n",
            "2020-05-14 14:58:19,676 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:58:19,678 EPOCH 45 done: loss 3.3800 - lr 0.0031\n",
            "2020-05-14 14:58:21,611 DEV : loss 3.39520525932312 - score 0.683\n",
            "2020-05-14 14:58:21,620 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 14:58:35,232 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:58:39,655 epoch 46 - iter 4/46 - loss 3.17786485 - samples/sec: 28.97\n",
            "2020-05-14 14:58:44,458 epoch 46 - iter 8/46 - loss 3.86147758 - samples/sec: 26.75\n",
            "2020-05-14 14:58:47,893 epoch 46 - iter 12/46 - loss 3.42791055 - samples/sec: 37.46\n",
            "2020-05-14 14:58:51,749 epoch 46 - iter 16/46 - loss 3.47390278 - samples/sec: 33.38\n",
            "2020-05-14 14:58:54,621 epoch 46 - iter 20/46 - loss 3.54275817 - samples/sec: 44.85\n",
            "2020-05-14 14:58:59,210 epoch 46 - iter 24/46 - loss 3.47704981 - samples/sec: 28.01\n",
            "2020-05-14 14:59:03,108 epoch 46 - iter 28/46 - loss 3.59933839 - samples/sec: 33.03\n",
            "2020-05-14 14:59:06,004 epoch 46 - iter 32/46 - loss 3.52147364 - samples/sec: 44.47\n",
            "2020-05-14 14:59:09,548 epoch 46 - iter 36/46 - loss 3.41054893 - samples/sec: 36.32\n",
            "2020-05-14 14:59:13,024 epoch 46 - iter 40/46 - loss 3.43798417 - samples/sec: 37.00\n",
            "2020-05-14 14:59:15,938 epoch 46 - iter 44/46 - loss 3.38693180 - samples/sec: 44.34\n",
            "2020-05-14 14:59:17,269 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:59:17,270 EPOCH 46 done: loss 3.3800 - lr 0.0031\n",
            "2020-05-14 14:59:19,179 DEV : loss 3.403414487838745 - score 0.6857\n",
            "Epoch    46: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2020-05-14 14:59:19,185 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 14:59:32,729 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 14:59:36,608 epoch 47 - iter 4/46 - loss 3.64153010 - samples/sec: 33.02\n",
            "2020-05-14 14:59:39,942 epoch 47 - iter 8/46 - loss 3.25268832 - samples/sec: 38.60\n",
            "2020-05-14 14:59:43,602 epoch 47 - iter 12/46 - loss 3.61864740 - samples/sec: 35.18\n",
            "2020-05-14 14:59:48,232 epoch 47 - iter 16/46 - loss 3.56837426 - samples/sec: 27.76\n",
            "2020-05-14 14:59:51,649 epoch 47 - iter 20/46 - loss 3.56622813 - samples/sec: 37.69\n",
            "2020-05-14 14:59:55,177 epoch 47 - iter 24/46 - loss 3.35734495 - samples/sec: 36.47\n",
            "2020-05-14 14:59:59,611 epoch 47 - iter 28/46 - loss 3.32534343 - samples/sec: 29.00\n",
            "2020-05-14 15:00:02,471 epoch 47 - iter 32/46 - loss 3.27167224 - samples/sec: 45.05\n",
            "2020-05-14 15:00:05,824 epoch 47 - iter 36/46 - loss 3.24032308 - samples/sec: 38.37\n",
            "2020-05-14 15:00:09,775 epoch 47 - iter 40/46 - loss 3.35135501 - samples/sec: 32.57\n",
            "2020-05-14 15:00:12,580 epoch 47 - iter 44/46 - loss 3.33368033 - samples/sec: 45.95\n",
            "2020-05-14 15:00:14,617 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:00:14,619 EPOCH 47 done: loss 3.3543 - lr 0.0016\n",
            "2020-05-14 15:00:16,554 DEV : loss 3.4058923721313477 - score 0.6816\n",
            "2020-05-14 15:00:16,563 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 15:00:30,076 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:00:33,709 epoch 48 - iter 4/46 - loss 3.23102108 - samples/sec: 35.25\n",
            "2020-05-14 15:00:37,161 epoch 48 - iter 8/46 - loss 2.94959587 - samples/sec: 37.28\n",
            "2020-05-14 15:00:41,790 epoch 48 - iter 12/46 - loss 3.26289338 - samples/sec: 27.77\n",
            "2020-05-14 15:00:45,053 epoch 48 - iter 16/46 - loss 3.36501684 - samples/sec: 39.44\n",
            "2020-05-14 15:00:49,297 epoch 48 - iter 20/46 - loss 3.42231426 - samples/sec: 30.29\n",
            "2020-05-14 15:00:52,715 epoch 48 - iter 24/46 - loss 3.56889933 - samples/sec: 37.67\n",
            "2020-05-14 15:00:56,776 epoch 48 - iter 28/46 - loss 3.44716357 - samples/sec: 31.69\n",
            "2020-05-14 15:01:00,384 epoch 48 - iter 32/46 - loss 3.40295754 - samples/sec: 35.68\n",
            "2020-05-14 15:01:04,348 epoch 48 - iter 36/46 - loss 3.33569868 - samples/sec: 32.44\n",
            "2020-05-14 15:01:07,639 epoch 48 - iter 40/46 - loss 3.32307843 - samples/sec: 39.09\n",
            "2020-05-14 15:01:11,789 epoch 48 - iter 44/46 - loss 3.38251011 - samples/sec: 30.99\n",
            "2020-05-14 15:01:13,048 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:01:13,049 EPOCH 48 done: loss 3.4204 - lr 0.0016\n",
            "2020-05-14 15:01:15,003 DEV : loss 3.407449722290039 - score 0.6857\n",
            "2020-05-14 15:01:15,012 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 15:01:28,526 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:01:32,492 epoch 49 - iter 4/46 - loss 2.29404694 - samples/sec: 32.29\n",
            "2020-05-14 15:01:36,568 epoch 49 - iter 8/46 - loss 3.10387833 - samples/sec: 31.54\n",
            "2020-05-14 15:01:39,947 epoch 49 - iter 12/46 - loss 2.96326346 - samples/sec: 38.09\n",
            "2020-05-14 15:01:43,472 epoch 49 - iter 16/46 - loss 2.81952334 - samples/sec: 36.55\n",
            "2020-05-14 15:01:46,851 epoch 49 - iter 20/46 - loss 3.04726992 - samples/sec: 38.11\n",
            "2020-05-14 15:01:50,415 epoch 49 - iter 24/46 - loss 3.18852401 - samples/sec: 36.10\n",
            "2020-05-14 15:01:53,222 epoch 49 - iter 28/46 - loss 3.19553531 - samples/sec: 45.93\n",
            "2020-05-14 15:01:57,519 epoch 49 - iter 32/46 - loss 3.21263939 - samples/sec: 29.91\n",
            "2020-05-14 15:02:01,969 epoch 49 - iter 36/46 - loss 3.42730725 - samples/sec: 28.88\n",
            "2020-05-14 15:02:05,743 epoch 49 - iter 40/46 - loss 3.39683927 - samples/sec: 34.09\n",
            "2020-05-14 15:02:09,402 epoch 49 - iter 44/46 - loss 3.36988439 - samples/sec: 35.16\n",
            "2020-05-14 15:02:11,408 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:02:11,409 EPOCH 49 done: loss 3.4334 - lr 0.0016\n",
            "2020-05-14 15:02:13,360 DEV : loss 3.405883312225342 - score 0.6816\n",
            "2020-05-14 15:02:13,366 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 15:02:26,950 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:02:30,807 epoch 50 - iter 4/46 - loss 3.84002948 - samples/sec: 33.22\n",
            "2020-05-14 15:02:33,773 epoch 50 - iter 8/46 - loss 3.71908921 - samples/sec: 43.46\n",
            "2020-05-14 15:02:37,168 epoch 50 - iter 12/46 - loss 3.52623777 - samples/sec: 37.90\n",
            "2020-05-14 15:02:40,195 epoch 50 - iter 16/46 - loss 3.22854294 - samples/sec: 42.55\n",
            "2020-05-14 15:02:44,039 epoch 50 - iter 20/46 - loss 3.37092105 - samples/sec: 33.48\n",
            "2020-05-14 15:02:47,730 epoch 50 - iter 24/46 - loss 3.27780472 - samples/sec: 34.87\n",
            "2020-05-14 15:02:50,587 epoch 50 - iter 28/46 - loss 3.28375545 - samples/sec: 45.09\n",
            "2020-05-14 15:02:55,174 epoch 50 - iter 32/46 - loss 3.37644060 - samples/sec: 28.03\n",
            "2020-05-14 15:02:58,843 epoch 50 - iter 36/46 - loss 3.36955989 - samples/sec: 35.07\n",
            "2020-05-14 15:03:01,995 epoch 50 - iter 40/46 - loss 3.36900782 - samples/sec: 40.84\n",
            "2020-05-14 15:03:07,213 epoch 50 - iter 44/46 - loss 3.35100814 - samples/sec: 24.61\n",
            "2020-05-14 15:03:08,712 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:03:08,713 EPOCH 50 done: loss 3.4066 - lr 0.0016\n",
            "2020-05-14 15:03:10,658 DEV : loss 3.404433250427246 - score 0.6884\n",
            "Epoch    50: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2020-05-14 15:03:10,665 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 15:03:24,193 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:03:28,842 epoch 51 - iter 4/46 - loss 5.15065563 - samples/sec: 27.55\n",
            "2020-05-14 15:03:31,969 epoch 51 - iter 8/46 - loss 4.25192592 - samples/sec: 41.18\n",
            "2020-05-14 15:03:35,600 epoch 51 - iter 12/46 - loss 4.07545131 - samples/sec: 35.44\n",
            "2020-05-14 15:03:38,929 epoch 51 - iter 16/46 - loss 3.69766083 - samples/sec: 38.69\n",
            "2020-05-14 15:03:42,122 epoch 51 - iter 20/46 - loss 3.46529858 - samples/sec: 40.32\n",
            "2020-05-14 15:03:45,992 epoch 51 - iter 24/46 - loss 3.41217309 - samples/sec: 33.26\n",
            "2020-05-14 15:03:49,414 epoch 51 - iter 28/46 - loss 3.31631612 - samples/sec: 37.63\n",
            "2020-05-14 15:03:53,075 epoch 51 - iter 32/46 - loss 3.47412081 - samples/sec: 35.14\n",
            "2020-05-14 15:03:57,690 epoch 51 - iter 36/46 - loss 3.48854597 - samples/sec: 27.84\n",
            "2020-05-14 15:04:01,397 epoch 51 - iter 40/46 - loss 3.44816619 - samples/sec: 34.72\n",
            "2020-05-14 15:04:04,510 epoch 51 - iter 44/46 - loss 3.33837166 - samples/sec: 41.35\n",
            "2020-05-14 15:04:06,704 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:04:06,705 EPOCH 51 done: loss 3.3693 - lr 0.0008\n",
            "2020-05-14 15:04:09,382 DEV : loss 3.4052324295043945 - score 0.6816\n",
            "2020-05-14 15:04:09,391 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 15:04:22,970 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:04:26,022 epoch 52 - iter 4/46 - loss 2.41142809 - samples/sec: 41.99\n",
            "2020-05-14 15:04:30,815 epoch 52 - iter 8/46 - loss 3.32082719 - samples/sec: 26.82\n",
            "2020-05-14 15:04:33,784 epoch 52 - iter 12/46 - loss 3.23678372 - samples/sec: 43.45\n",
            "2020-05-14 15:04:38,171 epoch 52 - iter 16/46 - loss 3.56791788 - samples/sec: 29.30\n",
            "2020-05-14 15:04:41,622 epoch 52 - iter 20/46 - loss 3.39598768 - samples/sec: 37.31\n",
            "2020-05-14 15:04:45,778 epoch 52 - iter 24/46 - loss 3.36439252 - samples/sec: 30.92\n",
            "2020-05-14 15:04:49,483 epoch 52 - iter 28/46 - loss 3.36885748 - samples/sec: 34.78\n",
            "2020-05-14 15:04:53,415 epoch 52 - iter 32/46 - loss 3.30571518 - samples/sec: 32.72\n",
            "2020-05-14 15:04:57,589 epoch 52 - iter 36/46 - loss 3.45065844 - samples/sec: 30.80\n",
            "2020-05-14 15:05:01,122 epoch 52 - iter 40/46 - loss 3.44203337 - samples/sec: 36.44\n",
            "2020-05-14 15:05:04,046 epoch 52 - iter 44/46 - loss 3.51159401 - samples/sec: 44.05\n",
            "2020-05-14 15:05:05,795 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:05:05,797 EPOCH 52 done: loss 3.4778 - lr 0.0008\n",
            "2020-05-14 15:05:07,758 DEV : loss 3.405383586883545 - score 0.6816\n",
            "2020-05-14 15:05:07,763 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 15:05:21,314 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:05:25,275 epoch 53 - iter 4/46 - loss 3.88738972 - samples/sec: 32.33\n",
            "2020-05-14 15:05:28,395 epoch 53 - iter 8/46 - loss 3.57923451 - samples/sec: 41.26\n",
            "2020-05-14 15:05:32,313 epoch 53 - iter 12/46 - loss 3.70805512 - samples/sec: 32.83\n",
            "2020-05-14 15:05:36,783 epoch 53 - iter 16/46 - loss 3.55619542 - samples/sec: 28.76\n",
            "2020-05-14 15:05:41,442 epoch 53 - iter 20/46 - loss 3.68460633 - samples/sec: 27.61\n",
            "2020-05-14 15:05:43,968 epoch 53 - iter 24/46 - loss 3.49416540 - samples/sec: 51.07\n",
            "2020-05-14 15:05:47,398 epoch 53 - iter 28/46 - loss 3.44083949 - samples/sec: 37.52\n",
            "2020-05-14 15:05:50,991 epoch 53 - iter 32/46 - loss 3.41582422 - samples/sec: 35.82\n",
            "2020-05-14 15:05:54,900 epoch 53 - iter 36/46 - loss 3.39045553 - samples/sec: 32.95\n",
            "2020-05-14 15:05:59,058 epoch 53 - iter 40/46 - loss 3.31850539 - samples/sec: 30.92\n",
            "2020-05-14 15:06:02,389 epoch 53 - iter 44/46 - loss 3.34909592 - samples/sec: 38.64\n",
            "2020-05-14 15:06:04,113 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:06:04,115 EPOCH 53 done: loss 3.3920 - lr 0.0008\n",
            "2020-05-14 15:06:06,055 DEV : loss 3.4036741256713867 - score 0.6857\n",
            "2020-05-14 15:06:06,065 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 15:06:19,543 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:06:22,485 epoch 54 - iter 4/46 - loss 3.14964604 - samples/sec: 43.55\n",
            "2020-05-14 15:06:27,035 epoch 54 - iter 8/46 - loss 4.15653989 - samples/sec: 28.26\n",
            "2020-05-14 15:06:30,868 epoch 54 - iter 12/46 - loss 3.84618670 - samples/sec: 33.58\n",
            "2020-05-14 15:06:33,688 epoch 54 - iter 16/46 - loss 3.70007537 - samples/sec: 45.73\n",
            "2020-05-14 15:06:37,081 epoch 54 - iter 20/46 - loss 3.83856676 - samples/sec: 37.93\n",
            "2020-05-14 15:06:41,202 epoch 54 - iter 24/46 - loss 3.82426906 - samples/sec: 31.20\n",
            "2020-05-14 15:06:44,181 epoch 54 - iter 28/46 - loss 3.64062882 - samples/sec: 43.27\n",
            "2020-05-14 15:06:47,572 epoch 54 - iter 32/46 - loss 3.52607686 - samples/sec: 37.96\n",
            "2020-05-14 15:06:51,391 epoch 54 - iter 36/46 - loss 3.48331097 - samples/sec: 33.68\n",
            "2020-05-14 15:06:55,280 epoch 54 - iter 40/46 - loss 3.44158456 - samples/sec: 33.07\n",
            "2020-05-14 15:06:58,769 epoch 54 - iter 44/46 - loss 3.40629609 - samples/sec: 36.87\n",
            "2020-05-14 15:07:00,497 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:07:00,499 EPOCH 54 done: loss 3.4272 - lr 0.0008\n",
            "2020-05-14 15:07:02,444 DEV : loss 3.3988585472106934 - score 0.6884\n",
            "Epoch    54: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2020-05-14 15:07:02,454 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 15:07:16,017 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:07:19,160 epoch 55 - iter 4/46 - loss 2.88537872 - samples/sec: 40.76\n",
            "2020-05-14 15:07:23,825 epoch 55 - iter 8/46 - loss 3.07349655 - samples/sec: 27.55\n",
            "2020-05-14 15:07:28,212 epoch 55 - iter 12/46 - loss 3.34422727 - samples/sec: 29.31\n",
            "2020-05-14 15:07:31,564 epoch 55 - iter 16/46 - loss 3.33583137 - samples/sec: 38.40\n",
            "2020-05-14 15:07:34,300 epoch 55 - iter 20/46 - loss 3.12591712 - samples/sec: 47.10\n",
            "2020-05-14 15:07:37,592 epoch 55 - iter 24/46 - loss 3.13689844 - samples/sec: 39.09\n",
            "2020-05-14 15:07:41,368 epoch 55 - iter 28/46 - loss 3.14967567 - samples/sec: 34.05\n",
            "2020-05-14 15:07:44,348 epoch 55 - iter 32/46 - loss 3.13836875 - samples/sec: 43.20\n",
            "2020-05-14 15:07:48,998 epoch 55 - iter 36/46 - loss 3.25403990 - samples/sec: 27.63\n",
            "2020-05-14 15:07:52,469 epoch 55 - iter 40/46 - loss 3.30765404 - samples/sec: 37.11\n",
            "2020-05-14 15:07:56,845 epoch 55 - iter 44/46 - loss 3.42346064 - samples/sec: 29.38\n",
            "2020-05-14 15:07:58,051 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:07:58,052 EPOCH 55 done: loss 3.4244 - lr 0.0004\n",
            "2020-05-14 15:08:00,049 DEV : loss 3.3993051052093506 - score 0.6884\n",
            "2020-05-14 15:08:00,059 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 15:08:13,595 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:08:17,601 epoch 56 - iter 4/46 - loss 2.34972867 - samples/sec: 31.98\n",
            "2020-05-14 15:08:20,509 epoch 56 - iter 8/46 - loss 2.71261497 - samples/sec: 44.30\n",
            "2020-05-14 15:08:24,492 epoch 56 - iter 12/46 - loss 3.03360455 - samples/sec: 32.31\n",
            "2020-05-14 15:08:27,729 epoch 56 - iter 16/46 - loss 2.95253816 - samples/sec: 39.78\n",
            "2020-05-14 15:08:32,078 epoch 56 - iter 20/46 - loss 3.34438137 - samples/sec: 29.58\n",
            "2020-05-14 15:08:35,168 epoch 56 - iter 24/46 - loss 3.28660737 - samples/sec: 41.66\n",
            "2020-05-14 15:08:39,039 epoch 56 - iter 28/46 - loss 3.27295599 - samples/sec: 33.23\n",
            "2020-05-14 15:08:42,371 epoch 56 - iter 32/46 - loss 3.34850809 - samples/sec: 38.63\n",
            "2020-05-14 15:08:46,241 epoch 56 - iter 36/46 - loss 3.56381803 - samples/sec: 33.22\n",
            "2020-05-14 15:08:50,420 epoch 56 - iter 40/46 - loss 3.53443232 - samples/sec: 30.78\n",
            "2020-05-14 15:08:54,100 epoch 56 - iter 44/46 - loss 3.48749807 - samples/sec: 34.96\n",
            "2020-05-14 15:08:55,939 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:08:55,940 EPOCH 56 done: loss 3.4321 - lr 0.0004\n",
            "2020-05-14 15:08:57,871 DEV : loss 3.400390625 - score 0.6884\n",
            "2020-05-14 15:08:57,880 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 15:09:11,422 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:09:14,096 epoch 57 - iter 4/46 - loss 2.81093758 - samples/sec: 47.91\n",
            "2020-05-14 15:09:18,110 epoch 57 - iter 8/46 - loss 3.43523422 - samples/sec: 32.04\n",
            "2020-05-14 15:09:21,201 epoch 57 - iter 12/46 - loss 3.48850997 - samples/sec: 41.67\n",
            "2020-05-14 15:09:23,981 epoch 57 - iter 16/46 - loss 3.28681687 - samples/sec: 46.33\n",
            "2020-05-14 15:09:27,587 epoch 57 - iter 20/46 - loss 3.30566486 - samples/sec: 35.70\n",
            "2020-05-14 15:09:31,309 epoch 57 - iter 24/46 - loss 3.44941108 - samples/sec: 34.58\n",
            "2020-05-14 15:09:34,153 epoch 57 - iter 28/46 - loss 3.38882408 - samples/sec: 45.31\n",
            "2020-05-14 15:09:38,476 epoch 57 - iter 32/46 - loss 3.40624895 - samples/sec: 29.78\n",
            "2020-05-14 15:09:41,639 epoch 57 - iter 36/46 - loss 3.30459546 - samples/sec: 40.69\n",
            "2020-05-14 15:09:45,680 epoch 57 - iter 40/46 - loss 3.27681043 - samples/sec: 31.81\n",
            "2020-05-14 15:09:50,002 epoch 57 - iter 44/46 - loss 3.38217149 - samples/sec: 29.73\n",
            "2020-05-14 15:09:51,875 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:09:51,876 EPOCH 57 done: loss 3.3334 - lr 0.0004\n",
            "2020-05-14 15:09:53,842 DEV : loss 3.401278018951416 - score 0.6884\n",
            "2020-05-14 15:09:53,848 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 15:10:07,388 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:10:11,830 epoch 58 - iter 4/46 - loss 4.36475128 - samples/sec: 28.83\n",
            "2020-05-14 15:10:14,491 epoch 58 - iter 8/46 - loss 3.28248322 - samples/sec: 48.45\n",
            "2020-05-14 15:10:17,803 epoch 58 - iter 12/46 - loss 3.10937645 - samples/sec: 38.85\n",
            "2020-05-14 15:10:21,586 epoch 58 - iter 16/46 - loss 2.96819773 - samples/sec: 34.00\n",
            "2020-05-14 15:10:24,348 epoch 58 - iter 20/46 - loss 2.92070560 - samples/sec: 46.68\n",
            "2020-05-14 15:10:27,826 epoch 58 - iter 24/46 - loss 3.10787381 - samples/sec: 37.07\n",
            "2020-05-14 15:10:31,659 epoch 58 - iter 28/46 - loss 3.05225670 - samples/sec: 33.56\n",
            "2020-05-14 15:10:35,432 epoch 58 - iter 32/46 - loss 3.11033392 - samples/sec: 34.14\n",
            "2020-05-14 15:10:39,387 epoch 58 - iter 36/46 - loss 3.13335684 - samples/sec: 32.51\n",
            "2020-05-14 15:10:43,556 epoch 58 - iter 40/46 - loss 3.18985465 - samples/sec: 30.83\n",
            "2020-05-14 15:10:47,768 epoch 58 - iter 44/46 - loss 3.34928966 - samples/sec: 30.53\n",
            "2020-05-14 15:10:49,436 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:10:49,437 EPOCH 58 done: loss 3.3634 - lr 0.0004\n",
            "2020-05-14 15:10:51,371 DEV : loss 3.401881694793701 - score 0.6884\n",
            "Epoch    58: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2020-05-14 15:10:51,382 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 15:11:04,871 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:11:08,941 epoch 59 - iter 4/46 - loss 4.29869568 - samples/sec: 31.47\n",
            "2020-05-14 15:11:12,598 epoch 59 - iter 8/46 - loss 3.39688213 - samples/sec: 35.18\n",
            "2020-05-14 15:11:16,469 epoch 59 - iter 12/46 - loss 3.11042036 - samples/sec: 33.24\n",
            "2020-05-14 15:11:20,049 epoch 59 - iter 16/46 - loss 3.38009540 - samples/sec: 35.93\n",
            "2020-05-14 15:11:24,078 epoch 59 - iter 20/46 - loss 3.37377946 - samples/sec: 31.91\n",
            "2020-05-14 15:11:27,659 epoch 59 - iter 24/46 - loss 3.50439172 - samples/sec: 35.94\n",
            "2020-05-14 15:11:31,880 epoch 59 - iter 28/46 - loss 3.55810735 - samples/sec: 30.48\n",
            "2020-05-14 15:11:35,965 epoch 59 - iter 32/46 - loss 3.45222205 - samples/sec: 31.49\n",
            "2020-05-14 15:11:39,328 epoch 59 - iter 36/46 - loss 3.44472026 - samples/sec: 38.31\n",
            "2020-05-14 15:11:42,620 epoch 59 - iter 40/46 - loss 3.49658584 - samples/sec: 39.24\n",
            "2020-05-14 15:11:45,875 epoch 59 - iter 44/46 - loss 3.41504443 - samples/sec: 39.56\n",
            "2020-05-14 15:11:48,133 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:11:48,135 EPOCH 59 done: loss 3.4240 - lr 0.0002\n",
            "2020-05-14 15:11:50,068 DEV : loss 3.4013431072235107 - score 0.6884\n",
            "2020-05-14 15:11:50,074 BAD EPOCHS (no improvement): 1\n",
            "2020-05-14 15:12:03,646 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:12:07,490 epoch 60 - iter 4/46 - loss 3.16367587 - samples/sec: 33.32\n",
            "2020-05-14 15:12:11,070 epoch 60 - iter 8/46 - loss 2.46333706 - samples/sec: 35.93\n",
            "2020-05-14 15:12:15,028 epoch 60 - iter 12/46 - loss 3.02350630 - samples/sec: 32.51\n",
            "2020-05-14 15:12:18,744 epoch 60 - iter 16/46 - loss 3.17004798 - samples/sec: 34.63\n",
            "2020-05-14 15:12:22,909 epoch 60 - iter 20/46 - loss 3.17726284 - samples/sec: 30.87\n",
            "2020-05-14 15:12:26,689 epoch 60 - iter 24/46 - loss 3.20583019 - samples/sec: 34.07\n",
            "2020-05-14 15:12:31,194 epoch 60 - iter 28/46 - loss 3.27851399 - samples/sec: 28.54\n",
            "2020-05-14 15:12:34,150 epoch 60 - iter 32/46 - loss 3.27459478 - samples/sec: 43.58\n",
            "2020-05-14 15:12:37,609 epoch 60 - iter 36/46 - loss 3.42455639 - samples/sec: 37.22\n",
            "2020-05-14 15:12:41,077 epoch 60 - iter 40/46 - loss 3.40557263 - samples/sec: 37.14\n",
            "2020-05-14 15:12:45,532 epoch 60 - iter 44/46 - loss 3.39217506 - samples/sec: 28.85\n",
            "2020-05-14 15:12:47,124 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:12:47,125 EPOCH 60 done: loss 3.4310 - lr 0.0002\n",
            "2020-05-14 15:12:49,100 DEV : loss 3.400890350341797 - score 0.6884\n",
            "2020-05-14 15:12:49,106 BAD EPOCHS (no improvement): 2\n",
            "2020-05-14 15:13:02,667 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:13:07,743 epoch 61 - iter 4/46 - loss 4.16176116 - samples/sec: 25.23\n",
            "2020-05-14 15:13:10,540 epoch 61 - iter 8/46 - loss 3.19922863 - samples/sec: 46.04\n",
            "2020-05-14 15:13:13,918 epoch 61 - iter 12/46 - loss 3.02757255 - samples/sec: 38.10\n",
            "2020-05-14 15:13:18,060 epoch 61 - iter 16/46 - loss 2.95811285 - samples/sec: 31.05\n",
            "2020-05-14 15:13:21,630 epoch 61 - iter 20/46 - loss 2.78483912 - samples/sec: 36.05\n",
            "2020-05-14 15:13:24,369 epoch 61 - iter 24/46 - loss 3.00088558 - samples/sec: 47.06\n",
            "2020-05-14 15:13:27,624 epoch 61 - iter 28/46 - loss 3.27288185 - samples/sec: 39.57\n",
            "2020-05-14 15:13:30,924 epoch 61 - iter 32/46 - loss 3.31543038 - samples/sec: 39.09\n",
            "2020-05-14 15:13:35,647 epoch 61 - iter 36/46 - loss 3.48050920 - samples/sec: 27.20\n",
            "2020-05-14 15:13:39,408 epoch 61 - iter 40/46 - loss 3.42918560 - samples/sec: 34.20\n",
            "2020-05-14 15:13:43,871 epoch 61 - iter 44/46 - loss 3.43325465 - samples/sec: 28.79\n",
            "2020-05-14 15:13:45,255 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:13:45,256 EPOCH 61 done: loss 3.3837 - lr 0.0002\n",
            "2020-05-14 15:13:47,203 DEV : loss 3.400960683822632 - score 0.6884\n",
            "2020-05-14 15:13:47,212 BAD EPOCHS (no improvement): 3\n",
            "2020-05-14 15:14:00,690 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:14:04,805 epoch 62 - iter 4/46 - loss 3.96543062 - samples/sec: 31.88\n",
            "2020-05-14 15:14:09,047 epoch 62 - iter 8/46 - loss 3.82066411 - samples/sec: 30.30\n",
            "2020-05-14 15:14:13,005 epoch 62 - iter 12/46 - loss 4.08238610 - samples/sec: 32.48\n",
            "2020-05-14 15:14:16,057 epoch 62 - iter 16/46 - loss 3.71553291 - samples/sec: 42.20\n",
            "2020-05-14 15:14:20,914 epoch 62 - iter 20/46 - loss 3.64595009 - samples/sec: 26.46\n",
            "2020-05-14 15:14:25,202 epoch 62 - iter 24/46 - loss 3.59894021 - samples/sec: 29.98\n",
            "2020-05-14 15:14:28,783 epoch 62 - iter 28/46 - loss 3.67192566 - samples/sec: 35.93\n",
            "2020-05-14 15:14:31,813 epoch 62 - iter 32/46 - loss 3.56556078 - samples/sec: 42.51\n",
            "2020-05-14 15:14:35,490 epoch 62 - iter 36/46 - loss 3.48308341 - samples/sec: 35.01\n",
            "2020-05-14 15:14:39,959 epoch 62 - iter 40/46 - loss 3.49661008 - samples/sec: 28.78\n",
            "2020-05-14 15:14:42,881 epoch 62 - iter 44/46 - loss 3.40881295 - samples/sec: 44.08\n",
            "2020-05-14 15:14:44,512 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:14:44,514 EPOCH 62 done: loss 3.3928 - lr 0.0002\n",
            "2020-05-14 15:14:46,454 DEV : loss 3.400430202484131 - score 0.6884\n",
            "Epoch    62: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2020-05-14 15:14:46,463 BAD EPOCHS (no improvement): 4\n",
            "2020-05-14 15:15:00,055 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:15:00,056 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:15:00,059 learning rate too small - quitting training!\n",
            "2020-05-14 15:15:00,062 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:15:27,682 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-14 15:15:27,684 Testing using best model ...\n",
            "2020-05-14 15:15:31,376 loading file resources/taggers/example-ner/best-model.pt\n",
            "2020-05-14 15:16:23,199 0.7267\t0.6605\t0.692\n",
            "2020-05-14 15:16:23,200 \n",
            "MICRO_AVG: acc 0.529 - f1-score 0.692\n",
            "MACRO_AVG: acc 0.5063 - f1-score 0.6699\n",
            "LOC        tp: 437 - fp: 165 - fn: 175 - tn: 437 - precision: 0.7259 - recall: 0.7141 - accuracy: 0.5624 - f1-score: 0.7200\n",
            "ORG        tp: 104 - fp: 51 - fn: 94 - tn: 104 - precision: 0.6710 - recall: 0.5253 - accuracy: 0.4177 - f1-score: 0.5893\n",
            "PER        tp: 97 - fp: 24 - fn: 59 - tn: 97 - precision: 0.8017 - recall: 0.6218 - accuracy: 0.5389 - f1-score: 0.7004\n",
            "2020-05-14 15:16:23,203 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(7.2147, device='cuda:0'),\n",
              "  tensor(5.5177, device='cuda:0'),\n",
              "  tensor(4.9707, device='cuda:0'),\n",
              "  tensor(4.7452, device='cuda:0'),\n",
              "  tensor(4.9197, device='cuda:0'),\n",
              "  tensor(4.3801, device='cuda:0'),\n",
              "  tensor(4.0778, device='cuda:0'),\n",
              "  tensor(4.2329, device='cuda:0'),\n",
              "  tensor(3.9958, device='cuda:0'),\n",
              "  tensor(3.9063, device='cuda:0'),\n",
              "  tensor(3.8502, device='cuda:0'),\n",
              "  tensor(3.7256, device='cuda:0'),\n",
              "  tensor(3.6668, device='cuda:0'),\n",
              "  tensor(3.7321, device='cuda:0'),\n",
              "  tensor(3.6343, device='cuda:0'),\n",
              "  tensor(3.6623, device='cuda:0'),\n",
              "  tensor(3.6430, device='cuda:0'),\n",
              "  tensor(3.7386, device='cuda:0'),\n",
              "  tensor(3.6067, device='cuda:0'),\n",
              "  tensor(3.6919, device='cuda:0'),\n",
              "  tensor(3.5715, device='cuda:0'),\n",
              "  tensor(3.5724, device='cuda:0'),\n",
              "  tensor(3.4871, device='cuda:0'),\n",
              "  tensor(3.4999, device='cuda:0'),\n",
              "  tensor(3.4437, device='cuda:0'),\n",
              "  tensor(3.4879, device='cuda:0'),\n",
              "  tensor(3.6304, device='cuda:0'),\n",
              "  tensor(3.5714, device='cuda:0'),\n",
              "  tensor(3.5589, device='cuda:0'),\n",
              "  tensor(3.4859, device='cuda:0'),\n",
              "  tensor(3.5542, device='cuda:0'),\n",
              "  tensor(3.4005, device='cuda:0'),\n",
              "  tensor(3.4340, device='cuda:0'),\n",
              "  tensor(3.4047, device='cuda:0'),\n",
              "  tensor(3.4450, device='cuda:0'),\n",
              "  tensor(3.4306, device='cuda:0'),\n",
              "  tensor(3.4302, device='cuda:0'),\n",
              "  tensor(3.4166, device='cuda:0'),\n",
              "  tensor(3.4084, device='cuda:0'),\n",
              "  tensor(3.4262, device='cuda:0'),\n",
              "  tensor(3.4070, device='cuda:0'),\n",
              "  tensor(3.4179, device='cuda:0'),\n",
              "  tensor(3.4101, device='cuda:0'),\n",
              "  tensor(3.4033, device='cuda:0'),\n",
              "  tensor(3.3952, device='cuda:0'),\n",
              "  tensor(3.4034, device='cuda:0'),\n",
              "  tensor(3.4059, device='cuda:0'),\n",
              "  tensor(3.4074, device='cuda:0'),\n",
              "  tensor(3.4059, device='cuda:0'),\n",
              "  tensor(3.4044, device='cuda:0'),\n",
              "  tensor(3.4052, device='cuda:0'),\n",
              "  tensor(3.4054, device='cuda:0'),\n",
              "  tensor(3.4037, device='cuda:0'),\n",
              "  tensor(3.3989, device='cuda:0'),\n",
              "  tensor(3.3993, device='cuda:0'),\n",
              "  tensor(3.4004, device='cuda:0'),\n",
              "  tensor(3.4013, device='cuda:0'),\n",
              "  tensor(3.4019, device='cuda:0'),\n",
              "  tensor(3.4013, device='cuda:0'),\n",
              "  tensor(3.4009, device='cuda:0'),\n",
              "  tensor(3.4010, device='cuda:0'),\n",
              "  tensor(3.4004, device='cuda:0')],\n",
              " 'dev_score_history': [0.3026,\n",
              "  0.5275,\n",
              "  0.5412,\n",
              "  0.5605,\n",
              "  0.5781,\n",
              "  0.6132,\n",
              "  0.6401,\n",
              "  0.6208,\n",
              "  0.6227,\n",
              "  0.6307,\n",
              "  0.6304,\n",
              "  0.6449,\n",
              "  0.6426,\n",
              "  0.65,\n",
              "  0.6584,\n",
              "  0.6525,\n",
              "  0.6554,\n",
              "  0.6653,\n",
              "  0.6481,\n",
              "  0.6583,\n",
              "  0.668,\n",
              "  0.6708,\n",
              "  0.6638,\n",
              "  0.6694,\n",
              "  0.6872,\n",
              "  0.6829,\n",
              "  0.6667,\n",
              "  0.6814,\n",
              "  0.6639,\n",
              "  0.6857,\n",
              "  0.6802,\n",
              "  0.6817,\n",
              "  0.6805,\n",
              "  0.6898,\n",
              "  0.6735,\n",
              "  0.6776,\n",
              "  0.6886,\n",
              "  0.6857,\n",
              "  0.6844,\n",
              "  0.6789,\n",
              "  0.6789,\n",
              "  0.6763,\n",
              "  0.6857,\n",
              "  0.6803,\n",
              "  0.683,\n",
              "  0.6857,\n",
              "  0.6816,\n",
              "  0.6857,\n",
              "  0.6816,\n",
              "  0.6884,\n",
              "  0.6816,\n",
              "  0.6816,\n",
              "  0.6857,\n",
              "  0.6884,\n",
              "  0.6884,\n",
              "  0.6884,\n",
              "  0.6884,\n",
              "  0.6884,\n",
              "  0.6884,\n",
              "  0.6884,\n",
              "  0.6884,\n",
              "  0.6884],\n",
              " 'test_score': 0.692,\n",
              " 'train_loss_history': [16.681020757426385,\n",
              "  7.511734806973001,\n",
              "  6.397989138312962,\n",
              "  5.933489918708801,\n",
              "  5.514904872230861,\n",
              "  5.29548802583114,\n",
              "  5.057961217735125,\n",
              "  4.848466624384341,\n",
              "  4.790498111558997,\n",
              "  4.663749039173126,\n",
              "  4.486894052961598,\n",
              "  4.247959230257117,\n",
              "  4.26577499638433,\n",
              "  4.164838609488114,\n",
              "  4.017826733381852,\n",
              "  4.11849556280219,\n",
              "  4.063803631326427,\n",
              "  4.0413473352142,\n",
              "  3.992288454719212,\n",
              "  3.9138992869335674,\n",
              "  3.8932960370312566,\n",
              "  3.852216417374818,\n",
              "  3.8861412898353906,\n",
              "  3.8388166194376736,\n",
              "  3.796533799689749,\n",
              "  3.723695765370908,\n",
              "  3.774441008982451,\n",
              "  3.64863927208859,\n",
              "  3.6945899336234382,\n",
              "  3.6182037591934204,\n",
              "  3.536667502444723,\n",
              "  3.5211859371351157,\n",
              "  3.520676716514256,\n",
              "  3.4508349532666416,\n",
              "  3.552881396335104,\n",
              "  3.385028002054795,\n",
              "  3.450927768064582,\n",
              "  3.4677841741105784,\n",
              "  3.456348771634309,\n",
              "  3.3647120543148206,\n",
              "  3.3451743022255274,\n",
              "  3.397005081176758,\n",
              "  3.472449007241622,\n",
              "  3.3945226099180137,\n",
              "  3.379974388557932,\n",
              "  3.3800461577332537,\n",
              "  3.3543148584987805,\n",
              "  3.420433653437573,\n",
              "  3.43335497379303,\n",
              "  3.406597668709962,\n",
              "  3.3693278691043025,\n",
              "  3.477842305017554,\n",
              "  3.3920154234637385,\n",
              "  3.427162315534509,\n",
              "  3.424384726130444,\n",
              "  3.4321015140284663,\n",
              "  3.3334131836891174,\n",
              "  3.3633977071098657,\n",
              "  3.4240384503551153,\n",
              "  3.4309524323629295,\n",
              "  3.383735978085062,\n",
              "  3.392782175022623]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDfu7tXO5V1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restart training at any time\n",
        "from pathlib import Path\n",
        "\n",
        "checkpoint = '/content/drive/My Drive/resources/checkpoint.pt'\n",
        "trainer = ModelTrainer.load_checkpoint(checkpoint, corpus)\n",
        "trainer.train('resources/taggers/example-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              train_with_dev='True',\n",
        "              max_epochs=?,\n",
        "              checkpoint=True, \n",
        "              embeddings_storage_mode='gpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXEphnwWhQD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot weight traces \n",
        "plotter = Plotter()\n",
        "plotter.plot_weights('resources/taggers/example-ner/weights.txt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}